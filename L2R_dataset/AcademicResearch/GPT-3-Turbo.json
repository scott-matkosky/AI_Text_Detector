["This report discusses our implementation of AlexNet using Theano, running on multiple GPUs with naive data parallelism. Our performance on 2 GPUs matches the Caffe library running on 1 GPU. This is believed to be the first open-source Python-based AlexNet implementation available.", "We demonstrate that deep narrow Boltzmann machines can approximate probability distributions on their visible units effectively if they have enough hidden layers, each containing the same number of units as the visible layer. Additionally, within specific parameter ranges, we can analyze deep Boltzmann machines as feedforward networks. We establish both upper and lower limits on the necessary depth and width of these universal approximators. These findings clarify ideas related to undirected networks and demonstrate that deep narrow Boltzmann machines are as efficient as narrow sigmoid belief networks and restricted Boltzmann machines when considering current bounds for those models.", "By utilizing improvements in variational inference, we suggest improving recurrent neural networks by incorporating latent variables, creating Stochastic Recurrent Networks (STORNs). This model: i) can be trained using stochastic gradient techniques, ii) enables structured and multi-modal conditions at each time point, iii) includes a dependable estimator of the marginal likelihood, and iv) is an extension of deterministic recurrent neural networks. We assess the effectiveness of this approach using four polyphonic musical datasets and motion capture data.", "We introduce a novel framework for real-time adjustment of optimization hyperparameters called \"hot swapping\" during learning. This method, inspired by the explore-exploit strategy from the multi-armed bandit theory, is studied in the context of adaptive learning rate selection. Our experiments on a standard neural network demonstrate that hot swapping yields superior results compared to popular methods like AdaDelta and stochastic gradient with exhaustive hyperparameter search.", "Many modern multiclass and multilabel problems have vast output spaces, presenting significant computational challenges. Label embeddings emerge as a pivotal solution to enhance efficiency in such scenarios. Our innovative approach establishes a direct connection between rank-constrained estimation and low-dimensional label embeddings, leading to the development of a swift label embedding algorithm applicable in both multiclass and multilabel contexts. The outcome is a randomized algorithm for partial least squares, boasting exponential speed enhancements compared to traditional approaches. By applying our methodology to extensive public datasets such as the Large Scale Hierarchical Text Challenge and the Open Directory Project, we achieve cutting-edge results, showcasing the effectiveness of our techniques.", "Precise depiction of both explicit and implicit relationships within data is vital for enabling machines to carry out advanced and abstract reasoning tasks effectively. In this study, we present the methodology for weakly supervised learning of these inferences through our Dynamic Adaptive Network Intelligence (DANI) model. Our research showcases the cutting-edge performance of the DANI model in addressing question answering tasks within the bAbI dataset, which have posed challenges for current representation learning approaches (Weston et al., 2015).", "Spectral-based features like MFCC or PLP are typically relied upon by automatic speech recognition systems. These features are derived from existing knowledge in speech perception and production. However, recent advancements have showcased the effectiveness of convolutional neural networks in estimating phoneme probabilities solely based on raw speech signals. This data-driven approach has proven to be at least as effective, if not more so, than systems based on HMM/ANN with fewer parameters. Inspired by these findings, we explore the integration of a simple linear classifier within the CNN framework. This design allows the network to learn linearly separable features directly from the raw speech data. Our experiments demonstrate that this approach can achieve comparable, if not superior, performance compared to traditional MLP systems utilizing cepstral-based features.", "The neural-network training framework used in the Kaldi speech recognition toolkit is designed for training DNNs with large amounts of data on multiple GPU-equipped or multi-core machines. To be hardware-agnostic, the framework employs a method that involves averaging neural network parameters periodically and redistributing them to machines for further training. This method enables the use of multiple machines without generating excessive network traffic. Additionally, an approximate and efficient implementation of Natural Gradient for Stochastic Gradient Descent (NG-SGD) is used to improve the convergence of SGD on a single machine and enhance the effectiveness of the periodic-averaging method.", "We have created a new way to visualize and improve how learned representations handle invariances. Our method focuses on a particular type of invariance called linearization, where a transformation's effect is limited to a lower-dimensional space. By analyzing two different reference images and creating a sequence of images between them that is the shortest path in the representation space (a \"representational geodesic\"), we can evaluate if the learned representation properly captures the transformation between the images. Our findings show that a cutting-edge image classification network fails to represent translations, rotations, and dilations accurately, but we present a solution that improves the representation's ability to handle a variety of geometric transformations.", "Absolutely! Why does Deep Learning truly shine? What wondrous representations does it uncover? And how do those magnificent higher-order representations come into being? These burning questions are meticulously explored through the captivating lens of group theory, shedding new light on the remarkable world of Deep Learning. A key catalyst fueling the excitement in this field is the ingenious concept of {\\em pretraining}, where each layer unveils its treasures step by step by seeking the perfect generative model for the input samples. The profound implications of this seemingly simple idea are unearthed as we delve into the exquisite dance between orbits and stabilizers of group actions. While neural networks themselves may not conform to traditional group structures, the revelation of {\\em shadow} groups offers a dazzling glimpse into their interconnected world.\n\nIn this mesmerizing realm of shadow groups, the pretraining process transforms from a humble initialization ritual into a stirring quest for features with the most elegant orbits. These features, in their pure simplicity, come forth as the foundation stones upon which deep learning networks build their knowledge. It's no wonder then that these networks gravitate towards learning these fundamental features first. As we venture deeper into the layers, the same enchanting principle unfolds, mapping out the intricate landscape of higher-order representations. Witness how the complexity of representations blossoms with each layer, painting a vivid picture of discovery as we journey through the depths of Deep Learning. \ud83d\ude80\ud83c\udf1f", "Introducing the dynamic \"stacked what-where auto-encoders\" (SWWAE)! This innovative architecture combines discriminative and generative pathways, offering an all-encompassing strategy for supervised, semi-supervised, and unsupervised learning - all without the need for sampling during training! In the SWWAE framework, a Convolutional Net (Convnet) is used to encode the input, while a Deconvolutional Net (Deconvnet) is employed to generate the reconstruction. The objective function includes reconstruction terms that encourage the hidden states in the Deconvnet to closely resemble those of the Convnet. At each pooling layer, two sets of variables are produced: the \"what\" variables passed to the next layer, and the complementary \"where\" variables directed to the corresponding layer in the generative decoder. Let the SWWAE unleash the power of learning without limits!", "We study how to create word embeddings that are specialized for a specific type of word relationship. Our algorithm modifies an existing set of word vectors to make the new embeddings effective for predicting a certain type of word relationship. Our experiments demonstrate that using specialized embeddings can improve both the accuracy and speed of word prediction tasks.", "A sophisticated generative model has been devised for deep convolutional dictionary learning in multiple layers. Intriguingly, a novel probabilistic pooling operation has been seamlessly incorporated into the model, resulting in both efficient bottom-up (pretraining) and top-down (refinement) probabilistic learning. Empirical findings showcase the model's remarkable capacity for acquiring multi-layer features from images, leading to exceptional classification outcomes on the renowned MNIST and Caltech 101 datasets.", "Motivated by the advancements in generative modeling techniques, we present a novel model designed to create images based on textual descriptions. Our innovative approach involves generating images through an iterative patch-drawing process on a canvas, focusing on pertinent words in the input description. By training our model on the Microsoft COCO dataset, we conduct a comprehensive comparison with various baseline generative models across image generation and retrieval tasks. The results showcase the superior quality of our model's generated samples compared to existing methods, emphasizing its ability to produce unique image compositions aligning with previously unencountered caption descriptions in the dataset.", "Convolutional neural networks (CNNs) are effective on large datasets, but collecting labeled data can be difficult, and sometimes there is a lack of a sufficient amount of data for certain applications. The challenge lies in applying CNNs to small datasets because they tend to overfit quickly. Our solution is an efficient Bayesian CNN that provides better protection against overfitting on small datasets compared to traditional methods. This is achieved by incorporating a probability distribution over the CNN's kernels. We use Bernoulli variational distributions to approximate the model's complex posterior, without needing extra model parameters. From a theoretical perspective, we frame dropout network training as a form of inference in Bayesian neural networks. This allows us to implement our model using existing deep learning tools without increasing time complexity, while also uncovering a limitation in the field. Our approach demonstrates a significant enhancement in classification accuracy when compared to standard techniques and surpasses previously published state-of-the-art results for CIFAR-10.", "We present a novel approach for developing efficient convolutional neural networks (CNNs) using low-rank representations of convolutional filters. Instead of approximating filters in existing networks, we generate a set of compact basis filters from scratch. Through training, the network learns to combine these basis filters to create more complex and discriminative filters for image classification. Our method involves a unique weight initialization scheme that ensures effective initialization of connection weights in convolutional layers with various filter shapes.\n\nWe have successfully applied our approach to multiple CNN architectures and trained them from the ground up on datasets like CIFAR, ILSVRC, and MIT Places. Our results indicate similar or better accuracy compared to traditional CNNs, while significantly reducing computational requirements. For instance, enhancing the VGG-11 network with global max-pooling resulted in achieving similar validation accuracy with 41% less compute and only 24% of the original model parameters.\n\nMoreover, a refined version of our method improved the top-5 center-crop validation accuracy of the VGG-11 model to 89.7% while decreasing computation by 16%. Applying our technique to the GoogLeNet architecture yielded comparable accuracy with 26% less compute and 41% fewer parameters. Finally, we achieved similar accuracy improvements on a near state-of-the-art network for CIFAR by reducing compute by 46% and parameters by 55%.", "Distributed word representations have revolutionized various Natural Language Processing tasks, significantly enhancing performance. However, the conventional approach of obtaining only one representation per word fails to address the complexity of words with multiple meanings. This limitation adversely impacts both individual word representations and the overall language model. In our paper, we introduce a straightforward model that leverages cutting-edge techniques in word vector construction to capture different senses of polysemic words. Through our evaluation, we demonstrate how this model excels at distinguishing between various meanings of words efficiently.", "Introducing DENN, the revolutionary Diverse Embedding Neural Network designed to supercharge language models (LMs)! Unlike traditional LMs, a DENNLM switches things up by mapping input word history vectors onto multiple unique low-dimensional spaces, rather than confining them to a single high-dimensional realm. By promoting this diversity in sub-spaces during training using an enriched loss function, DENN opens up new possibilities for language modeling. Exciting experiments on the Penn Treebank dataset reveal the remarkable performance boost that a DENNLM can bring to the table.", "In the realm of Collaborative Filtering (CF), a classic method for predicting user ratings on items involves employing Matrix Factorization techniques. By deriving representations for users and items based on existing ratings, predictions can be made. However, these methods face a challenge when new users join without any previous ratings, referred to as the \"user cold-start\" issue. To address this, one common strategy is to request these new users to provide a few initial ratings. This study introduces a novel model that not only addresses this dual challenge of identifying pertinent questions for new users and constructing effective representations from limited data but also extends to traditional scenarios. The effectiveness of our model is demonstrated on multiple datasets, showcasing its ability to enhance performance in both standard and cold-start scenarios.", "We introduce NICE, a deep learning framework for modeling complex high-dimensional densities. NICE aims to learn a non-linear deterministic transformation of the data to map it to a latent space, resulting in independent latent variables. We use simple building blocks based on deep neural networks to learn complex transformations easily. The training criterion is the exact log-likelihood, making it tractable, with easy ancestral sampling. Our approach produces high-quality generative models for image datasets and can be used for inpainting.", "We are pleased to introduce Deep Linear Discriminant Analysis (DeepLDA), a cutting-edge approach that harnesses deep neural networks to learn separable latent representations in a seamless manner. Unlike traditional LDA techniques that focus on preserving class separability for dimensionality reduction in classification tasks, DeepLDA combines the power of LDA with the depth of neural networks to create a nonlinear extension of this classic method. Our innovative objective function encourages the network to generate feature distributions with low intra-class variance and high inter-class variance, based on the foundational LDA eigenvalue problem. Notably, our approach supports training through stochastic gradient descent and back-propagation, ensuring efficiency and effectiveness. Through rigorous evaluation on popular datasets like MNIST, CIFAR-10, and STL-10, DeepLDA has demonstrated competitive performance on MNIST and CIFAR-10, while surpassing a network trained with categorical cross entropy in a supervised setting on STL-10, showcasing its superior capabilities.", "The Layer-sequential unit-variance (LSUV) initialization is a straightforward method proposed for weight initialization in deep neural network learning. The method involves two steps: Firstly, initializing the weights of each convolution or inner-product layer with orthonormal matrices, followed by normalizing the output variance of each layer to one as you progress from the first to the final layer.\n\nExperimental results with various activation functions (such as maxout, ReLU, tanh) demonstrate that this initialization strategy allows for effective learning in deep networks. Specifically, it enables the training of deep networks with test accuracy that matches or surpasses standard methods. Furthermore, it achieves comparable speed to more complex initialization schemes tailored for very deep networks like FitNets and Highway.\n\nThe performance evaluation conducted on networks like GoogLeNet, CaffeNet, FitNets, and Residual nets reveals that LSUV initialization achieves state-of-the-art results or comes very close to it on popular datasets such as MNIST, CIFAR-10/100, and ImageNet.", "In this innovative approach, we present a parametric nonlinear transformation designed specifically to Gaussianize data extracted from natural images. The procedure involves linear transformation of the data, followed by normalization of each component through a combined measure of activity. This measure is computed by exponentiating a weighted sum of rectified and exponentiated elements along with a constant term. The transformation parameters, encompassing the linear transform, exponents, weights, and constant, are optimized across a natural image database. The optimization process directly targets the reduction of response negentropy. The resulting optimized transformation effectively Gaussianizes the data, significantly lowering mutual information between transformed components compared to traditional methods such as ICA and radial Gaussianization. Notably, the transformation is differentiable, enabling efficient inversion and establishment of a density model for images. Samples generated from this model closely resemble natural image patches. The model can also serve as a prior probability density for noise removal purposes. Furthermore, cascading the transformation by optimizing each layer with the Gaussianization objective offers a self-learning approach for refining deep network architectures without supervision.", "We introduce a new type of convolutional neural networks that are optimized for quick processing. Researchers have studied the redundancy of parameters in convolutional neural networks, specifically the weights of convolutional filters, and have developed various techniques to create a more efficient set of filters after training. In this study, we trained flattened networks using a series of one-dimensional filters in all directions in a 3D space to achieve similar performance to traditional convolutional networks. Testing on various datasets showed that the flattened layer can effectively replace 3D filters without sacrificing accuracy. The flattened convolution pipelines result in approximately twice the speed improvement during processing compared to the standard model due to a significant reduction in learning parameters. Additionally, this method eliminates the need for manual adjustments or post-processing after training.", "In this paper, we introduce a new deep learning framework called Purine. Purine represents a deep network as a structure called a bipartite graph (bi-graph), which is made up of connected operators and data tensors. Using this bi-graph concept makes it easy to solve networks with an event-driven task dispatcher. We show that various parallelism methods over GPUs and/or CPUs on one or multiple computers can be implemented universally through graph composition. This simplifies the need for researchers to code different parallelization techniques, and the same dispatcher can handle different types of graphs. By coordinating memory transfers with computations, we can significantly reduce communication delays, leading to faster processing times.", "The paper introduces the Variational Recurrent Auto-Encoder (VRAE) model as a fusion of the strengths of RNNs and SGVB. This model enables efficient unsupervised learning on time series data at scale by transforming the data into a latent vector representation. VRAE is a generative model, allowing the generation of data based on latent space samples. A key aspect of this research is the model's capacity to incorporate unlabeled data to assist in the supervised training of RNNs by initializing weights and network state.", "This paper promotes the concept of using density-based distributed embeddings by mapping words to Gaussian distributions rather than point vectors. This method offers several advantages, such as capturing uncertainty and asymmetries more effectively, as well as allowing for more expressive decision boundaries. Our study includes performance comparisons on word embedding benchmarks, explores the ability to model entailment and other asymmetric relationships, and delves into unique properties of these representations.", "Multipliers are the most resource-intensive arithmetic operators within the digital implementation of deep neural networks. Our research involves the training of cutting-edge neural networks, specifically Maxout networks, on three standardized datasets: MNIST, CIFAR-10, and SVHN. These networks are trained using three distinct numeric formats: floating point, fixed point, and dynamic fixed point. Our evaluation focuses on analyzing the impact of multiplication precision on the final error post-training for each dataset and format. Surprisingly, our findings indicate that significantly lower precision is not only adequate for executing trained networks but also for training them. Notably, our results show the feasibility of training Maxout networks using only 10-bit multiplications.", "Innovative approach alert! Our proposed method shakes up the traditional ways of semantic segmentation by utilizing Multiple Instance Learning (MIL) to slash annotation costs. Say goodbye to extensive supervision requirements! Our cutting-edge MIL formulation for multi-class semantic segmentation harnesses the power of a fully convolutional network. With just weak image-level labels, we embark on the journey of training a semantic segmentation model. This model undergoes end-to-end training, optimizing the representation and untangling the intricate pixel-image label connections. Imagine - no need for object proposal pre-processing and the luxury of accepting inputs of any size. The cherry on top? A pixelwise loss map to uncover those hidden instances. Our unique multi-class MIL loss seizes the additional supervision cues provided by images with multiple labels. Watch out, PASCAL VOC segmentation challenge \u2013 we're coming for you!", "Nested dropout presents an innovative approach to organizing representation units in autoencoders based on information content, all while maintaining reconstruction accuracy. Although initially utilized in unsupervised fully-connected autoencoders, we delve into its potential within the convolutional layers of CNNs trained via backpropagation. Our aim is to uncover if nested dropout can serve as a straightforward method to identify the ideal representation size for achieving desired accuracy in the context of various tasks and data complexities.", "This passage discusses the importance of stochastic gradient algorithms in large-scale learning problems and their success in machine learning. The convergence of these algorithms relies on selecting an appropriate learning rate and managing the noise in stochastic gradient estimates. The paper introduces a novel adaptive learning rate algorithm that uses curvature information to adjust learning rates automatically. By estimating the curvature of the loss function from local statistical properties of the stochastic gradients, the algorithm aims to improve convergence speed. Additionally, a variance reduction technique is proposed to enhance convergence rate. Preliminary experiments with deep neural networks show improved performance compared to traditional stochastic gradient algorithms.", "Enhance the readability of this text: When a three-dimensional object moves in relation to an observer, changes are observed on the image plane and in the visual output generated by a learned model. Our exploration centers around the concept that a high-quality visual representation will react consistently to shifts in the scene. By drawing on group representation theory, we prove that any such representation can be expressed as a blend of fundamental, irreducible components. We highlight a fascinating link between irreducibility and the statistical structure of the representation, revealing that irreducible components exhibit independence under specific circumstances. In scenarios where observation is incomplete - such as when a scene is projected onto the image plane - the motion group's effect on image space is not straightforward. This scenario necessitates working with a latent representation that transforms linearly to make accurate inferences. This concept is illustrated through a model involving rotating NORB objects, which utilizes a latent representation of the non-commutative 3D rotation group SO(3).", "This study compares different approaches for solving the Efficient Maximum Inner Product Search (MIPS) task, which is widely used in recommendation systems and classification. While previous research has explored solutions based on locality-sensitive hashing (LSH) and tree-based methods for approximate MIPS, this paper proposes a simpler approach using variants of the k-means clustering algorithm. By training a spherical k-means model after transforming the problem into a Maximum Cosine Similarity Search (MCSS), the study demonstrates that this straightforward method achieves significantly faster retrieval speeds with the same level of precision compared to existing hashing and tree-based methods. Additionally, the results indicate that this approach provides more robust retrievals in scenarios where the query data is noisy.", "A new generative model called the importance weighted autoencoder (IWAE) has been introduced as an alternative to the variational autoencoder (VAE). While both models share a similar architecture, the IWAE offers a strictly tighter log-likelihood lower bound by utilizing importance weighting. By employing multiple samples in the recognition network to approximate the posterior, the IWAE surpasses the VAE's assumptions and exhibits enhanced flexibility in modeling complex posteriors. Empirical evidence demonstrates that IWAEs are capable of capturing more intricate latent space representations than VAEs, resulting in superior test log-likelihood performance in density estimation tasks.", "This study explores the impact of using reduced precision data in Convolutional Neural Networks (CNNs) on network accuracy in classification tasks. Specifically, we investigate networks where each layer may utilize different precision data. Our main finding is that the tolerance of CNNs to reduced precision data not only varies across networks as commonly understood, but also within networks. Customizing precision at the layer level is promising as it has the potential to enhance energy efficiency and performance. This paper examines the variation in error tolerance across layers and proposes a method for determining a low precision setup for a network while preserving high accuracy. Through an analysis of a diverse range of CNNs, we demonstrate that compared to a standard setup using a 32-bit floating-point representation for all layers, it is possible to reduce the data footprint of these networks by an average of 74% and up to 92% with less than 1% loss in relative accuracy.", "Graph-based semi-supervised algorithms' efficiency depends on the underlying instance graph. Instances are initially represented in vector form before being linked in the graph. The graph construction uses a metric in the vector space to determine connection weights, typically using a distance or similarity measure based on the Euclidean norm. However, the Euclidean norm may not always be the best choice for optimal performance. Our proposed algorithm focuses on learning the most suitable vector representation to create an efficient solving graph for the task.", "This paper proposes explicitly modeling a visual-semantic hierarchy encompassing hypernymy, textual entailment, and image captioning as special cases. We introduce a method for learning ordered representations, demonstrating its effectiveness in various image and language tasks. Our approach enhances hypernym prediction and image-caption retrieval performance compared to existing methods.", "Introducing local distributional smoothness (LDS), a novel concept enhancing statistical models by infusing smoothness within the model's distribution. Our proposed LDS, termed virtual adversarial training (VAT), advocates a unique regularization approach. Unlike conventional adversarial training, VAT extracts the adversarial direction solely from the model's distribution without relying on label information, widening its application to semi-supervised learning contexts. Formulating the adversarial direction requires minimal computational expense - for instance, in a neural network, calculating the approximated gradient of the LDS demands no more than three pairs of forward and back propagations. Evaluating this methodology on MNIST, SVHN, and NORB datasets demonstrated superior performance over existing training techniques, falling second only to a cutting-edge generative model.", "Convolutional Network models have achieved remarkable recognition results with the help of large labeled datasets. However, manual annotation of data is often unfeasible in many scenarios. In our work, we investigate the effectiveness of discriminatively-trained Convnets when utilizing noisy labels, where each image is associated with a potentially inaccurate freely available label. We propose the incorporation of an additional noise layer in the network to align the network outputs with the noisy label distribution. The parameters of this noise layer can be learned during the training process with minor adjustments to existing deep learning frameworks. We present our methodology across various datasets, incorporating large-scale experiments on the ImageNet classification benchmark.", "We offer innovative guaranteed methods for training feedforward neural networks with sparse connectivity. By building on prior work for training linear networks, we demonstrate the adaptability of these techniques for training non-linear networks. Our approach focuses on the moments related to the input's score function and label, demonstrating that their factorization reliably produces the weight matrix of the initial layer in a deep network under favorable conditions. In application, our method can serve as efficient initializers for gradient descent.", "Transformed text:\n\n\"Connecting smaller linguistic units into cohesive texts through discourse relations poses a fascinating challenge. Understanding the underlying semantics of linked sentences is essential, yet identifying these relations automatically is often complex. An additional layer of intricacy lies in capturing not just the meaning of individual sentences within these relations, but also accounting for the connections between lower-level elements like entity mentions. Our innovative approach involves deriving distributional meaning representations by building them up through the syntactic parse tree. What sets our method apart is the inclusion of entity mentions in the computation process, achieved through a unique downward compositional pass. By considering not only the distributional representations of sentences but also those of their coreferent entity mentions, our system has demonstrated vast improvements over existing models in predicting implicit discourse relations within the Penn Discourse Treebank.\"", "In this groundbreaking work, we introduce an innovative approach that combines two cutting-edge research trends: autonomous discovery of surface meanings like semantic roles and breaking down relationships in text and databases. Our cutting-edge model comprises two crucial components: 1) an encoding system: a sophisticated semantic role labeling model that anticipates roles using a vast set of syntactic and lexical features; 2) a reconstruction system: a tensor factorization model that uses roles to forecast argument fillers. By jointly refining these components to minimize mistakes in argument reconstruction, our method generates roles that closely resemble those in well-established resources. Our technique competes head-to-head with the most precise role creation strategies in English, even surpassing them without relying on any predetermined language specifics.", "The concept of a metric is crucial in machine learning tasks like classification, clustering, and ranking. Despite the lack of solid theoretical guarantees on a classifier's ability to generalize using a specific metric, the $(\\epsilon, \\gamma, \\tau)$-good similarity function framework (Balcan et al., 2008) tried to establish a connection between similarity function properties and linear classifier performance. This paper expands on this theory by introducing a new generalization bound for the classifier, incorporating the algorithmic robustness framework.", "Introducing the multiplicative recurrent neural network \u2013 a dynamic model that excels at capturing the essence of language and its nuanced expressions. Our exploration focuses on its application in fine-grained sentiment analysis, highlighting its versatility and prowess. By drawing parallels to matrix-space models and unveiling the unique approach of the multiplicative recurrent net, we demonstrate its superiority over Elman-type networks and matrix-space models in sentiment analysis tasks. Our results showcase the model's impressive capabilities, achieving comparable performance to structural deep models on the esteemed Stanford Sentiment Treebank, all without the complexities of parsing trees.", "Searching for the lowest points of a real-valued non-convex function in a vast dimensional space presents a formidable challenge in the realm of science. We unveil compelling evidence suggesting that certain functions, operating within expansive domains, exhibit a slender range of values encompassing the majority of their critical points. This dynamic sharply contrasts with the scenario seen in lower dimensions, where this range is noticeably broad. Our simulations are aligned with existing theoretical frameworks on spin glasses, affirming the emergence of such a distinctive range as the dimensionality approaches infinity. In addition, our experiments involving teacher-student networks utilizing the MNIST dataset vividly demonstrate a comparable trend in deep networks. Notably, both gradient descent and stochastic gradient descent methodologies are capable of achieving this milestone within an equivalent number of steps.", "We have developed a new statistical model for photographic images that describes the local responses of a set of linear filters as jointly Gaussian, with zero mean and a slowly varying covariance across the image. By optimizing the filters to reduce the nuclear norms of their local activations, we promote a flexible kind of sparsity that is not dependent on a specific dictionary or coordinate system. These optimized filters are oriented and bandpass, exhibiting significant local correlation in their responses. We demonstrate that images can be almost perfectly reconstructed using only estimates of the local filter response covariances, with minimal degradation in quality compared to low-rank approximations. This approach shows great potential for tasks such as denoising, compression, and texture representation, and could serve as a useful foundation for hierarchical decomposition methods.", "Most modern convolutional neural networks (CNNs) used for object recognition typically consist of alternating convolution and max-pooling layers followed by a few fully connected layers. In this study, we reassess the current state of object recognition from small images using convolutional networks, exploring the necessity of individual components in the architecture. Our investigation reveals that max-pooling can be effectively substituted by a convolutional layer with an increased stride without compromising accuracy on various image recognition benchmarks. Leveraging this insight, along with recent advancements in simplifying network structures, we propose a novel architecture composed exclusively of convolutional layers. This architecture demonstrates competitive or even superior performance on multiple object recognition datasets such as CIFAR-10, CIFAR-100, and ImageNet. To scrutinize the network, we introduce an innovative variation of the \"deconvolution approach\" for visualizing features learned by CNNs, extending its applicability to a broader spectrum of network configurations compared to existing methods.", "We created a new type of activation function for neural networks called a piecewise linear function. This function is customized for each neuron and learned using gradient descent. By using this adaptive activation function, we were able to enhance the performance of deep neural network models compared to traditional static activation functions like rectified linear units. This improvement led to achieving top-notch results on various datasets, including CIFAR-10 (7.51%), CIFAR-100 (30.83%), and a benchmark related to Higgs boson decay modes in high-energy physics.", "This study presents a greedy parser constructed on neural networks, employing an innovative compositional sub-tree representation. The greedy parser, along with the compositional process, undergo joint training and are inherently interdependent. The compositional process yields a compact vector representation that encapsulates both syntactic (parsing tags) and semantic (words) sub-trees. Composition and tagging are accomplished through continuous representations (of words or tags) and recurrent neural networks. This approach attains an F1 performance comparable to prominent existing parsers, while offering a notable speed advantage due to the parser's inherently greedy nature. A fully operational implementation of the presented method is made available.", "Revised phrasing: Adequate lateral connections have been demonstrated to facilitate higher layers of a denoising autoencoder (dAE) in focusing on invariant representations. Unlike conventional autoencoders, where detailed information must be processed through the top layers, the inclusion of lateral connections from the encoder to the decoder alleviates this requirement. It has been established that abstract invariant features can be transformed into detailed reconstructions by allowing invariant features to modulate the strength of these lateral connections. Experimental comparisons involving three dAE structures with modulated and additive lateral connections, as well as no lateral connections, were conducted using real-world images. The results of these experiments confirm that augmenting modulated lateral connections to the model serves to: 1) enhance the accuracy of the probability model for inputs, as indicated by improved denoising performance; 2) accelerate the progression towards higher layers in the development of invariant representations; and 3) foster the creation of varied invariant poolings.", "We introduce a novel approach to visualize and fine-tune the invariances learned by representations. Our method, based on linearization, tests for a specific form of invariance where the effect of a transformation is limited to a lower-dimensional subspace. By synthesizing a sequence of images between two reference images through a representational geodesic, we aim to demonstrate the efficacy of this method. We apply this technique to evaluate the invariance characteristics of a leading image classification network, identifying issues with transformations such as translation, rotation, and dilation. We propose a solution to address these shortcomings, which successfully enables the representation to linearize various geometric image transformations.", "Genomics are revolutionizing medical practice and research by offering invaluable insights into disease mechanisms and enhancing therapeutic strategies, especially in cancer. Predicting patient outcomes through complex genomic profiling is crucial for advancing genomic medicine, though it poses challenges for current survival analysis methods. Our study focuses on utilizing neural networks to learn genomic representations for predicting cancer patient survival, showcasing superior performance compared to traditional survival analysis techniques using brain tumor data.", "Current methods that integrate both additive and multiplicative neural units rely on predefined operations or necessitate discrete optimizations, resulting in heightened computational complexity during training. In this study, we introduce a new transfer function, grounded in non-integer functional iteration, that can dynamically adjust each neuron's operation from addition to multiplication in a smooth and differentiable manner. This innovative approach seamlessly incorporates the choice between addition and multiplication into the standard backpropagation training process.", "One challenge in training deep neural networks stems from inadequate scaling across layers, leading to problems such as exploding gradients. Traditionally, these scaling issues have been mitigated through meticulous scale-conserving initialization. In this study, we explore how preserving scale, or isometry, can be advantageous not only at initialization but throughout training. Introducing two methods to uphold isometry \u2013 one exact and one stochastic \u2013 our initial experiments reveal that both determinant and scale-normalization techniques can significantly enhance the learning process. Our findings indicate that prioritizing isometry early on and throughout training accelerates the learning process.", "We have upgraded Stochastic Gradient Variational Bayes to reveal the mysteries hidden in the weights of Stick-Breaking processes. Our breakthrough leads to the creation of a revolutionary Stick-Breaking Variational Autoencoder (SB-VAE), a Bayesian nonparametric marvel with a latent representation that dynamically shifts in size. Through our experiments, we've proven that the SB-VAE, along with its semi-supervised version, uncover remarkably powerful latent structures that frequently surpass the capabilities of traditional Gaussian VAEs.", "Unleash the power of unsupervised learning on imbalanced data with our cutting-edge approach! Conquering the challenge of imbalanced data, our innovative latent variable model breaks new ground by partitioning the latent space into a shared space and a private space. Leveraging the latest advancements in Gaussian Process Latent Variable Models, we introduce a revolutionary kernel formulation that not only segregates the latent space but also unleashes an efficient variational inference method. Witness the exceptional performance of our model as it outshines traditional approaches when applied to an imbalanced medical image dataset.", "GANs are deep generative models based on a two-player minimax game. To improve learning of the generator, we introduce an algorithm that repeats density ratio estimation and f-divergence minimization. This approach provides a fresh perspective on GANs and leverages insights from research on density ratio estimation, focusing on stable divergences and useful relative density ratios.", "The intersection of natural language processing (NLP) and cheminformatics is highlighted in this paper, discussing the application of NLP methods in classification problems. By analyzing the standard textual representation of compounds known as SMILES, a connection between these two diverse fields is established. The study focuses on predicting activity against a target protein, a key aspect of computer-aided drug design. The experiments conducted demonstrate the capability to surpass the performance of manually crafted representations and provide valuable structural insights into the decision-making process.", "We present a neural network design and a training method to generate factorized symbolic representations. Our approach involves learning these concepts through sequential frame observations, where most of the hidden representation components are predicted from the previous frame except for a few discrete gating units. These gating units capture the variations in the subsequent frame, representing symbolic concepts. We showcase the effectiveness of our method on datasets featuring facial transformations in 3D and Atari 2600 games.", "We examine the eigenvalues of the Hessian of a loss function both before and after training. The eigenvalue distribution consists of two main components: the bulk, which is mostly centered around zero, and the edges, which are spread out further from zero. Our findings provide empirical support for the bulk representing the degree of over-parameterization in the system, while the edges are influenced by the input data.", "We present a parametric nonlinear transformation designed specifically for the Gaussianization of data extracted from natural images. The process involves the linear transformation of the data, followed by normalization of each component using a pooled activity measure. This measure is determined by exponentiating a weighted sum of rectified and exponentiated components along with a constant term. The parameters of the entire transformation (including the linear transform, exponents, weights, and constant) are optimized using a database of natural images by directly minimizing the negentropy of the responses.\n\nThe optimized transformation effectively Gaussianizes the data, resulting in a notable reduction in the mutual information between transformed components compared to other methods like ICA and radial Gaussianization. This transformation, which is differentiable and can be easily inverted, establishes a density model on images. We provide evidence that samples generated by this model closely resemble natural image patches.\n\nWe showcase the utility of this model as a prior probability density that proves valuable in filtering out additive noise. Furthermore, we illustrate that the transformation can be stacked in a cascading manner, with each layer optimized using the Gaussianization objective. This approach offers an unsupervised means of refining a deep network architecture.", "Approximate variational inference is a strong method for modeling intricate probability distributions. Recent developments enable the learning of probabilistic models for sequences that make use of spatial and temporal patterns. We utilize a Stochastic Recurrent Network (STORN) to analyze time series data from robots. Our assessment confirms the capability to effectively identify anomalies in real-time as well as offline.", "We introduce a universal scenario to evaluate agents' efficiency in gathering information through training and testing. Our framework involves tasks where agents must explore partially observed environments to find information fragments that can be assembled to achieve different objectives. By utilizing deep architectures and reinforcement learning methods, we design agents capable of solving these tasks. We guide the agents' behavior by incorporating both external and internal rewards. Our experiments show that these agents learn to actively and intelligently search for new information to minimize uncertainty and effectively utilize acquired information.", "We introduce a new approach to enhance neural network language models by incorporating recent history into their predictions. Our model, inspired by memory augmented networks, stores past hidden activations in memory and retrieves them using a dot product with the current hidden activation. This efficient mechanism can handle large memory sizes effectively. Additionally, we establish a connection between using external memory in neural networks and cache models used in count-based language models. Experimenting with various language model datasets, we show that our method outperforms recent memory augmented networks significantly.", "Inspired by the advancements in generative models, we present a novel approach aimed at creating images based on natural language prompts. Our innovative model works by iteratively sketching patches on a canvas while focusing on key terms in the description. By training it on the Microsoft COCO dataset, we scrutinize its performance against various existing generative models across image creation and retrieval assignments. We showcase that our model excels in producing superior quality images compared to conventional methods, offering fresh scene compositions that align with previously unencountered captions in the dataset.", "We've come up with a cool way to train several neural networks at the same time! Basically, we use the tensor trace norm to make sure the networks share parameters, which helps them learn from each other. Unlike other models, we don't decide in advance which layers share parameters. Our framework figures out the best sharing strategy based on the data.", "This groundbreaking paper introduces an actor-critic deep reinforcement learning agent equipped with experience replay, setting a new standard for stability, efficiency, and exceptional performance across complex environments. Notably, the agent excels in the rigorous Atari domain, comprising 57 games, as well as various continuous control challenges. To achieve this superior performance, the paper pioneers novel strategies such as truncated importance sampling with bias correction, innovative stochastic dueling network architectures, and a cutting-edge trust region policy optimization technique.", "We introduce an innovative approach to creating pop music using a hierarchical Recurrent Neural Network. The hierarchy of layers in our model is designed to incorporate our understanding of the composition of pop music. The lower layers focus on generating melodies, while the upper layers create drum patterns and chords. Through human studies, we demonstrate that music generated using our framework is preferred over that produced by Google's recent method. Furthermore, we showcase two applications of our model: neural dancing and karaoke, as well as neural story singing.", "Several machine learning classifiers are susceptible to adversarial perturbations, which are alterations made to inputs in order to alter a classifier's output without noticeably changing the input to human observers. In this study, three techniques are utilized to identify adversarial images. Adversaries seeking to evade detection need to reduce the unusual characteristics of the adversarial images, otherwise, their attempts will be unsuccessful. The primary detection method highlights that adversarial images demonstrate an atypical focus on lower-ranked principal components derived from Principal Component Analysis (PCA). Additional detection methods, along with a detailed saliency map, are provided in an appendix.", "We introduce an innovative approach to crafting efficient convolutional neural networks (CNNs) - by leveraging low-rank representations of the convolutional filters. Instead of simply approximating pre-existing filters with more efficient versions, we make strides by initiating a new wave - training a collection of small basis filters from the ground up. As the network undergoes training, it learns to amalgamate these base filters into intricate, superior filters that shine in the realm of image classification. Enter our novel weight initialization scheme, paving the way for effective commencement of connection weights within convolutional layers consisting of divergent filter shapes. Our methodology has undergone rigorous validation, spanning various CNN architectures trained from the ground up utilizing CIFAR, ILSVRC, and MIT Places datasets.\n\nThe fruits of our labor reveal results that not only match but often surpass the accuracy of conventional CNNs, all while consuming significantly lesser computational resources. Applying our approach to an enhanced rendition of the VGG-11 network, integrated with global max-pooling, we attain a comparable validation accuracy while cutting compute usage by a substantial 41% and shrinking the model parameters to just a quarter of the original VGG-11's. A refined version of our technique boasts a 1 percentage point accuracy hike over the improved VGG-11, culminating in a top-notch center-crop validation accuracy of 89.7% - all while reducing computation by 16% compared to the original VGG-11 model. Transitioning to the GoogLeNet architecture in ILSVRC, we secure similar accuracy metrics with a sizable 26% reduction in compute resources and a 41% decrease in model parameters. Embarking on a high-performance network tailored for CIFAR, we achieve akin accuracy levels with a substantial 46% drop in computational load and a 55% reduction in parameters.", "Introducing Layer-Sequential Unit-Variance (LSUV) Initialization - an innovative approach to weight initialization for deep neural network learning. This method guarantees high performance by pre-initializing weights with orthonormal matrices and normalizing output variance. Experimentation with various activation functions proves that this strategy enables the training of ultra-deep networks with exceptional accuracy and speed. LSUV outperforms standard techniques and is on par with sophisticated methods tailored for very deep nets like FitNets and Highway. Impressive results are observed across popular architectures and datasets, including GoogLeNet, CaffeNet, FitNets, and Residual nets, achieving state-of-the-art or near-state-of-the-art performance on MNIST, CIFAR-10/100, and ImageNet datasets.", "This paper improves upon Kiperwasser & Goldberg (2016) by utilizing neural attention in a more sophisticated graph-based dependency parser with biaffine classifiers. Our parser achieves top-tier performance on standard treebanks for six languages, including 95.7% UAS and 94.1% LAS on the English PTB dataset. This makes it the highest-performing parser on this benchmark, surpassing Kiperwasser & Goldberg (2016) by 1.8% and 2.2%. Our parser is also comparable to the best transition-based parser, achieving 95.8% UAS and 94.6% LAS. We identify key hyperparameters that greatly impact parsing accuracy, leading to significant improvements over other graph-based parsers.", "It's super important for machines to understand both the obvious and hidden connections in data if they want to tackle tougher and more abstract challenges. Our Dynamic Adaptive Network Intelligence (DANI) model is great at learning these kinds of inferences with just a little bit of supervision. We've seen awesome results using DANI for question answering in the bAbI dataset, which has been a tough nut to crack for other methods (Weston et al., 2015).", "Spherical data can be found in many applications and it plays a crucial role in various scenarios. By modeling the discretized sphere as a graph, we are able to handle non-uniformly distributed, partial, and changing samplings with ease. Additionally, graph convolutions offer a computational advantage over spherical convolutions. To further enhance the model's performance by exploiting rotational symmetries, we explore rotation equivariance using the graph neural network proposed by Defferrard et al. (2016). Our experiments demonstrate promising results in addressing rotation-invariant learning tasks. You can access the code and examples on GitHub at https://github.com/SwissDataScienceCenter/DeepSphere.", "The widespread use of Convolutional Neural Networks (CNNs) is limited by their high computational complexity, particularly on mobile devices. Hardware accelerators offer a promising solution to decrease both execution time and power consumption. Developing accelerators involves crucial steps in hardware-oriented model approximation. This study introduces Ristretto, a framework that assesses a CNN by examining the numerical resolution employed to represent weights and outputs of convolutional and fully connected layers. Ristretto can simplify models by utilizing fixed-point arithmetic and representation rather than floating point. Additionally, Ristretto refines the resulting fixed-point network. With a maximum error tolerance of 1%, Ristretto effectively simplifies CaffeNet and SqueezeNet to 8-bit. The Ristretto code is accessible for use.", "Let's talk about how different painting styles give us a wide range of ways to create images. By understanding and capturing these styles effectively, we can really grasp the essence of paintings and artwork in general. In this study, we're looking into making a deep network that can easily capture a painting's artistic style. We found that this network can work with various painting styles thanks to a cool technique that puts each painting on a map in a certain space. With this model, users can mix and match painting styles to create something new and unique. This research is a step forward in creating detailed models of paintings and understanding the patterns in artistic styles.", "Sum-Product Networks (SPNs) are a class of hierarchical graphical models that balance expressiveness and tractability. LearnSPN, an algorithm for SPNs, employs hierarchical co-clustering to detect similar entities and features simultaneously. The original LearnSPN algorithm assumes all variables are discrete without missing data. We present MiniSPN, a simplified version of LearnSPN that offers improved speed and can handle missing data and various types of features common in real-world applications. MiniSPN's performance is showcased on standard benchmark datasets as well as two datasets sourced from Google's Knowledge Graph. These datasets demonstrate high rates of missingness and a mix of discrete and continuous features.", "Recent studies in deep neural networks have predominantly been centered around enhancing accuracy levels. However, did you know that within a given accuracy threshold, there could be various DNN architectures that deliver the same results? It's fascinating to note that opting for smaller DNN architectures when aiming for equivalent accuracy can provide an array of benefits. These compact designs not only demand less communication between servers during distributed training but also require minimal bandwidth when transferring models from the cloud to autonomous vehicles. Furthermore, their suitability for deployment on hardware with restricted memory, such as FPGAs, sets them apart.\n\nIntroducing SqueezeNet, a revolutionary small DNN architecture that promises immense advantages. Surpassing AlexNet's accuracy levels on ImageNet, SqueezeNet achieves this feat with a fraction of the parameters - a whopping 50x fewer, to be exact. Even more astonishing is the ability to compress SqueezeNet to less than 0.5MB, making it a mere 510x smaller than AlexNet. Intrigued to explore further? You can access the groundbreaking SqueezeNet architecture for download here: [https://github.com/DeepScale/SqueezeNet](https://github.com/DeepScale/SqueezeNet)", "In this paper, we introduce the Query-Reduction Network (QRN), a variant of Recurrent Neural Network (RNN) designed to handle short-term and long-term dependencies for question answering over multiple facts. QRN views context sentences as triggers for state changes, refining the original query with each observed trigger. Our experiments demonstrate QRN's superior performance in bAbI QA, dialog tasks, and real goal-oriented dialog datasets. Moreover, QRN enables parallelization on the RNN's time axis, resulting in a significant reduction in training and inference time complexity.", "We present a language-agnostic approach for automated generation of groups of semantically similar clusters of entities, accompanied by sets of \"outlier\" elements. This method enables an intrinsic evaluation of word embeddings for outlier detection purposes. Utilizing this methodology, we curated a standardized dataset named WikiSem500 and assessed various cutting-edge embeddings. The findings reveal a notable correlation between the effectiveness on this dataset and the performance in sentiment analysis tasks.", "Recurrent neural networks are commonly employed in forecasting temporal data due to their intricate deep feedforward design that enables them to grasp complex sequential patterns. Researchers suggest that incorporating top-down feedback into these networks could be a crucial aspect in distinguishing similar patterns based on a broader context. In this study, we propose surprisal-driven recurrent networks, which incorporate previous error data into their new predictions. This is done by continually analyzing the variance between the most recent predictions and the real observations. Additionally, we demonstrate that this approach outperforms other stochastic and completely deterministic techniques in the character-level prediction task on the enwik8 dataset, achieving a 1.37 BPC on the test section of the text.", "Generative Adversarial Networks, although excelling in generative tasks, are often seen as unstable and prone to missing certain modes. This issue is believed to stem from the unique functional shape of the trained discriminators in high-dimensional spaces, which can hinder training progress or lead the model to assign excessive probability mass in incorrect directions. To address these challenges, we propose various regularization techniques that significantly enhance the stability of GAN training. By leveraging these regularizers, we aim to improve the balanced distribution of probability mass across data distribution modes, consequently offering a comprehensive solution to the problem of missing modes especially in the initial training stages.", "Navigating the intricate landscape of sample complexity and safety in teaching policies through reinforcement learning for real-world tasks is no easy feat, especially when employing sophisticated function approximators like deep neural networks. It's a dance between using model-based methods, where a simulated world echoes the real one, to conquer data challenges. But the devil lies in the details as differences between these simulated and real worlds create hurdles during training.\n\nEnter the innovative EPOpt algorithm! This cutting-edge approach embraces an ensemble of simulated worlds and the art of adversarial training to cultivate policies that are resilient and can seamlessly adapt across a diverse array of potential scenarios, even unforeseen ones. By leveraging the power of source domain adaptation and approximate Bayesian techniques, the algorithm fine-tunes itself with real-world information to paint a more accurate representation of its environment.\n\nIn essence, learning through a dynamically evolving model ensemble, coupled with domain adaptation strategies, bestows the advantages of both robustness and profound learning capabilities.", "We present Divnet, a new method for training networks with diverse neurons. Divnet captures neuronal diversity by using a technique called Determinantal Point Process (DPP) on neurons in a layer. It selects a diverse subset of neurons using DPP and merges redundant neurons with the selected ones. Divnet is more structured and adaptable compared to existing methods for promoting neuronal diversity, which helps in regularization. This approach allows for efficient optimization of network structure, leading to smaller networks without compromising performance. Additionally, Divnet's focus on diversity and neuron merging is compatible with other techniques that aim to reduce network memory usage. Our experiments confirm that, when pruning neural networks, Divnet outperforms other methods significantly.", "Graph-based semi-supervised algorithms work better when they are applied on a graph made up of instances. These instances typically start off as vectors before being connected to form a graph. The way the graph is created depends on a metric in the vector space that determines how strongly the entities are connected. Normally, a common choice for this metric is a distance or similarity measure based on the euclidean norm. However, we believe that sometimes the euclidean norm may not be the best fit for solving the task effectively. Therefore, we introduce an algorithm that focuses on finding the most suitable vector representation to construct a graph, allowing us to efficiently solve the task at hand.", "In training Deep Neural Networks, a big challenge we face is keeping them from getting overly fixated on the training data, a problem known as overfitting. Many techniques like tweaking the data and using creative regularizers like Dropout have been suggested to address this issue without needing tons of data. In our study, we introduce a new regularizer called DeCov that helps immensely in curbing overfitting (seen in the gap between training and validation performance) and promoting better overall learning. Our regularizer pushes for varied and unique features in Deep Neural Networks by reducing the similarities in how different hidden layers respond. While this idea isn't entirely new, it's surprising that it hasn't been widely used as a regularizer in teaching these models. Tests on different datasets and model setups consistently show that our approach reduces overfitting and tends to either keep or improve the network's ability to generalize, often outperforming even the popular Dropout technique.", "We research online batch selection strategies for AdaDelta and Adam, two leading stochastic gradient-based optimization methods, to boost training efficiency. By ranking datapoints based on loss values and selecting batches accordingly, our approach accelerates both algorithms by approximately 5x on the MNIST dataset.", "We are thrilled to present an incredibly innovative and highly scalable approach for semi-supervised learning on graph-structured data! Our method is powered by a cutting-edge variant of convolutional neural networks that operate directly on graphs. Through a localized first-order approximation of spectral graph convolutions, we have carefully crafted a convolutional architecture that showcases efficiency and exceptional performance. \n\nWhat truly sets our model apart is its ability to scale linearly in the number of graph edges while learning hidden layer representations that capture the essence of both local graph structures and key nodes' features. In a series of rigorous experiments on citation networks and a knowledge graph dataset, our approach has not just outperformed but truly excelled beyond related methods by a substantial margin. Your journey to enhanced semi-supervised learning awaits with our groundbreaking solution! \ud83d\ude80\ud83c\udf1f", "We present a model called Energy-based Generative Adversarial Network (EBGAN). In this model, the discriminator acts like an energy function that assigns low energies to areas close to the real data and higher energies to other areas. The generator works to create samples with minimal energies, while the discriminator identifies and gives high energies to these generated samples. By treating the discriminator as an energy function, we can use different architectures and loss functions beyond the typical binary classifier with logistic output. For example, in one version of EBGAN, an auto-encoder setup is used with the reconstruction error as the energy rather than a traditional discriminator. This method shows more consistent performance during training compared to standard GANs. Furthermore, we demonstrate that a single-scale architecture can successfully produce high-resolution images.", "Recent research in deep learning has led to many new architecture designs. Some groups new to deep learning may feel overwhelmed by the variety of options and end up using older architectures like Alexnet. Our goal is to help bridge this gap by summarizing the key principles from recent deep learning research for designing neural network architectures. We also introduce innovative architectures like Fractal of FractalNet, Stagewise Boosting Networks, and Taylor Series Networks. You can find our Caffe code and prototxt files at https://github.com/iPhysicist/CNNDesignPatterns. We hope our work inspires others to build upon it.", "Machine comprehension (MC), which involves answering questions based on a provided context paragraph, requires understanding the complex interactions between the two. Lately, attention mechanisms have been successfully integrated into MC tasks. These approaches typically utilize attention to focus on specific parts of the context, summarize the information with a fixed-size vector, connect attentions over time, and often deploy uni-directional attention. In our study, we present the Bi-Directional Attention Flow (BIDAF) network, a multi-stage hierarchical process that captures context information at various granular levels and leverages bi-directional attention flow to create a query-aware context representation without premature summarization. Our experiments demonstrate that the BIDAF model outperforms existing methods and achieves state-of-the-art performance on the Stanford Question Answering Dataset (SQuAD) and the CNN/DailyMail cloze test.", "Despite advances in model learning and posterior inference, mastering deep generative models continues to pose a significant challenge, particularly in dealing with discrete hidden variables. This paper delves into the realm of Helmholz machines, where the generative model is paired with an auxiliary inference model, aiming to tackle this challenge head-on. Previous learning algorithms have often fallen short, as they merely optimize approximations of the desired marginal log-likelihood. In a departure from this approach, we introduce a novel class of algorithms grounded in stochastic approximation (SA) theory of the Robbins-Monro type, enabling direct optimization of the marginal log-likelihood while also minimizing the inclusive KL-divergence. This cutting-edge learning algorithm is aptly named joint SA (JSA). Furthermore, we devise a sophisticated MCMC operator tailored specifically for JSA. Our experiments on the MNIST datasets reveal that JSA consistently outperforms competing algorithms such as RWS in mastering complex models.", "Object detection using deep neural networks typically involves passing numerous potential bounding boxes through a neural network for each image. These bounding boxes are closely related as they come from the same image. This study explores utilizing feature patterns at the image level to streamline the neural network used for all bounding boxes. By removing units with minimal activation in the image, we can notably decrease the network's parameter count. Findings from the PASCAL 2007 Object Detection Challenge reveal that around 40% of units in certain fully-connected layers can be removed without significantly affecting the detection outcome.", "Modeling interactions between features significantly boosts the performance of machine learning solutions across various fields, such as recommender systems and sentiment analysis! Enter Exponential Machines (ExM), a cutting-edge predictor that captures all interactions of every order. By leveraging the innovative Tensor Train (TT) format to represent a vast tensor of parameters, ExM enhances model regularization and enables fine-tuning of the underlying parameters. Our pioneering stochastic Riemannian optimization approach empowers the training of models with a staggering 2^160 entries. Our results showcase ExM's unparalleled performance on synthetic data with high-order interactions and its exceptional competitiveness on the MovieLens 100K recommender system dataset when compared to high-order factorization machines. Get ready to witness the future of machine learning with Exponential Machines!", "Introducing Deep Variational Bayes Filters (DVBF), a novel technique for unsupervised learning and identifying latent Markovian state space models. DVBF utilizes advancements in Stochastic Gradient Variational Bayes to handle complex input data effectively, including sequences like images with temporal and spatial connections, without requiring specific domain expertise. Experimental results demonstrate that allowing backpropagation through transitions enforces state space assumptions, enhances information content in the latent embedding, and facilitates accurate long-term forecasting.", "Traditional goal-oriented dialog systems often involve extensive domain-specific manual work, limiting their ability to adapt to new domains. End-to-end dialog systems, however, overcome this constraint by training all components directly from the dialogs. While recent successes in chit-chat dialog are promising, they may not translate well to goal-oriented scenarios. This paper introduces a test platform to evaluate the effectiveness of end-to-end dialog systems in goal-oriented applications, with a focus on restaurant reservation tasks. These tasks involve handling sentences and symbols to engage in conversations, make API calls, and utilize the call outputs. Our study demonstrates that an end-to-end dialog system utilizing Memory Networks shows potential, learning to execute complex tasks with promising yet not flawless performance. We validate these findings by comparing our system to a manual slot-filling baseline using data from the Dialog State Tracking Challenge (Henderson et al., 2014a) and data from an online concierge service, showing consistent results across both datasets.", "Adversarial training regularizes supervised learning algorithms, while virtual adversarial training extends them to semi-supervised settings. However, both methods involve perturbing input vectors, which is not ideal for sparse high-dimensional inputs like one-hot word representations. To address this, we propose perturbing word embeddings in a recurrent neural network for text applications. Our method achieves state-of-the-art results on various tasks and improves both the quality of word embeddings and model training by reducing overfitting. Code can be found at https://github.com/tensorflow/models/tree/master/research/adversarial_text.", "Unsupervised learning of probabilistic models is a significant challenge in machine learning. Designing models with tractable learning, sampling, inference, and evaluation is crucial for solving this task. By utilizing real-valued non-volume preserving (real NVP) transformations, we expand the space of such models with powerful invertible and learnable transformations. This results in an unsupervised learning algorithm that offers exact log-likelihood computation, sampling, inference of latent variables, and an interpretable latent space. We showcase the model's effectiveness in modeling natural images on four datasets by demonstrating sampling, log-likelihood evaluation, and latent variable manipulations.", "This paper seeks to explore the perspective shift in examining the view-manifold structure across the various layers of Convolutional Neural Networks (CNN). It delves into essential queries such as the attainment of viewpoint invariance in the learned CNN representation, the mechanisms through which this invariance is realized, whether it involves collapsing or separating view manifolds, and the specific layer where view invariance is established. Additionally, the paper investigates experimental techniques to quantitatively assess the structure of the view manifold at each CNN layer and evaluates how fine-tuning a pre-trained CNN on a multi-view dataset impacts the representation at different layers of the network. A devised methodology to measure the deformation and degeneracy of view manifolds in various CNN layers is proposed, with the presented findings shedding light on the answers to these critical questions.", "Bilinear models offer richer representations than linear models and have been employed in various visual tasks such as object recognition, segmentation, and visual question-answering, achieving state-of-the-art performance by leveraging the enhanced representations. However, bilinear representations are often high-dimensional, which can limit their utility in computationally intensive tasks. To address this, we introduce low-rank bilinear pooling using Hadamard product to create an efficient attention mechanism for multimodal learning. Our approach surpasses compact bilinear pooling in visual question-answering tasks, achieving state-of-the-art results on the VQA dataset and demonstrating superior efficiency.", "Importance-weighted autoencoders aim to maximize a more restrictive bound on the marginal likelihood compared to the standard evidence lower bound. Our alternative interpretation is that they optimize the standard variational lower bound by employing a more intricate distribution. We show the formal derivation of this finding, introduce a stricter lower bound, and illustrate the underlying importance-weighted distribution.", "We provide a generalization bound for feedforward neural networks based on the spectral norm of the layers and the Frobenius norm of the weights, using PAC-Bayes analysis.", "In this paper, we introduce a method to improve Generative Adversarial Networks by providing direct energy estimates for samples. Our proposed flexible adversarial training framework guarantees the generator converges to the true data distribution while enabling the discriminator to retain density information at the global optimum. We derive the analytical solution and analyze its properties. To enhance trainability, we introduce two effective approximation techniques. Empirical results support our theoretical analysis, demonstrating the discriminator's ability to recover the energy of the data distribution.", "In this study, we conduct outlier detection by utilizing ensembles of neural networks derived through variational approximation of the posterior within a Bayesian neural network framework. The variational parameters are acquired through sampling from the genuine posterior via gradient descent. We demonstrate that our outlier detection outcomes are analogous to those achieved through other effective ensembling techniques.", "We introduce two straightforward methods to decrease parameter count and speed up training for large Long Short-Term Memory (LSTM) networks: one involves breaking down the LSTM matrix into two smaller matrices through \"matrix factorization by design,\" and the other involves partitioning the LSTM matrix, inputs, and states into separate groups. Both techniques enable the faster training of large LSTM networks to near state-of-the-art perplexity levels while requiring fewer RNN parameters.", "We found new and surprising results while training neural networks. Our aim is to learn more about how neural networks work by looking into these findings. We discovered these behaviors by using Cyclical Learning Rates (CLR) and linear network interpolation. Some of these behaviors include unexpected changes in training loss and fast training. For instance, we show that CLR can lead to better testing accuracy even with high learning rates. You can access the files to replicate our findings at https://github.com/lnsmith54/exploring-loss", "Machine learning models frequently encounter constraints and trade-offs during test-time that were not encountered during training-time. For instance, a computer vision model working on a compact device might have to carry out inference in real-time, while a translation model working on a cell phone could aim to limit its average computation time to enhance power efficiency. In this study, we introduce a mixture-of-experts model and demonstrate how to adjust its test-time resource allocation for each input using reinforcement learning. Our approach is validated on a simple MNIST-based illustration.", "This paper explores adversarial attacks on deep reinforcement learning policies, comparing the impact of using adversarial examples versus random noise. We introduce a new method that leverages the value function to minimize the number of adversarial injections needed for a successful attack. Additionally, we examine the effects of re-training on random noise and FGSM perturbations on the resilience against adversarial examples.", "This paper introduces variational continual learning (VCL), a framework that combines online variational inference (VI) and recent advances in Monte Carlo VI for neural networks to address continual learning challenges. VCL can train both deep discriminative and generative models in complex settings where tasks evolve over time and new tasks emerge. Experimental results demonstrate VCL's superiority over current continual learning methods across various tasks by preventing catastrophic forgetting automatically.", "In this paper, we tackle the challenge of determining the best size for a neural network without expensive trial and error. We introduce a method called nonparametric neural networks, which optimizes network size in a single training session. Our approach limits network growth with an L_p penalty to ensure effectiveness. We expand the network by adding new units and removing unnecessary ones using an L_2 penalty. To optimize this process, we created a new algorithm called adaptive radial-angular gradient descent (AdaRad), which has shown positive outcomes.", "The Natural Language Inference (NLI) task involves determining the logical relationship between a natural language premise and hypothesis. Our Interactive Inference Network (IIN) introduces a new type of neural network architecture that achieves a deep understanding of sentence pairs by hierarchically extracting semantic features from their interaction space. We demonstrate that the interaction tensor, with its attention weights, contains crucial semantic information for solving natural language inference tasks, and that a denser tensor captures more complex semantic details. One specific model, the Densely Interactive Inference Network (DIIN), showcases outstanding performance on both large-scale NLI datasets and the challenging Multi-Genre NLI (MultiNLI) dataset, achieving over a 20% error reduction compared to the best existing system.", "The capacity to implement neural networks in real-world, safety-critical applications is significantly restricted by the existence of adversarial samples: slightly altered inputs that are incorrectly classified by the network. In recent times, multiple methods have been suggested to enhance resilience against adversarial samples --- however, a majority of these have swiftly been found to be susceptible to future attacks. For instance, more than half of the defenses presented in papers approved at ICLR 2018 have already been compromised. Our solution to this challenge involves utilizing formal verification strategies. We demonstrate the ability to create adversarial samples with provably minimal alterations: taking an arbitrary neural network and input example, we can generate adversarial samples that are guaranteed to have minimal alteration. By adopting this method, we prove that one of the recent ICLR defense techniques, adversarial retraining, effectively increases the level of alteration needed to create adversarial samples by a factor of 4.2.", "We adapt Stochastic Gradient Variational Bayes to conduct posterior inference for the weights of Stick-Breaking processes. This innovation enables the creation of a Stick-Breaking Variational Autoencoder (SB-VAE), which is a Bayesian nonparametric iteration of the variational autoencoder featuring a latent representation with variable dimensionality. Our experiments show that the SB-VAE, along with a semi-supervised version, can learn remarkably discriminatory latent representations that frequently surpass those produced by Gaussian VAEs.", "We present a framework for concurrently training multiple neural networks. All models' parameters are constrained using the tensor trace norm, promoting parameter reuse among the networks. This approach underscores the concept of multi-task learning. Unlike numerous deep multi-task learning models, we avoid specifying a predefined parameter-sharing strategy by tying parameters in specific layers. Our framework allows for sharing among all suitable layers and enables a data-driven discovery of the sharing strategy.", "This paper introduces a deep reinforcement learning agent that combines actor-critic methods with experience replay. The agent is stable, efficient in using samples, and excels in difficult scenarios such as the 57-game Atari domain and various continuous control tasks. The paper proposes new techniques like truncated importance sampling, stochastic dueling network structures, and a trust region policy optimization method to achieve these results.", "Machine learning models can be tricked by slight modifications in the input, known as adversarial perturbations, which change the model's prediction without being easily noticeable to humans. We use three approaches to identify these manipulated images. To evade our detection, attackers need to make the adversarial images appear less unusual. Our most effective method shows that these images put a strange focus on less important elements from a statistical analysis technique called Principal Component Analysis (PCA). Additional detection methods and a visual aid can be found in an attached section.", "We present a cutting-edge approach to kernel learning that harnesses the power of Fourier analysis to understand translation-invariant or rotation-invariant kernels. Our innovative technique generates a series of feature maps that continuously enhance the SVM margin. By establishing strong theoretical guarantees for optimality and generalization, we view our algorithm as engaging in a dynamic online equilibrium search within a strategic two-player min-max game. Extensive testing on both artificial and actual datasets showcases the scalability and substantial advancements achieved compared to traditional random features-based methods.", "State-of-the-art deep reading comprehension models are absolutely crushing it with recurrent neural nets in the driver's seat! While their sequential nature is a perfect match for language, the limitation on parallelization within an instance can sometimes slow things down in critical scenarios. But wait, we've got an exciting solution for you! Introducing a convolutional architecture as an alternative to those recurrent models. By swapping out recurrent units with simple dilated convolutional units, we're achieving mind-blowing results on two question answering tasks. And guess what? We're also zooming past the competition with up to two orders of magnitude speedups for question answering. Let the excitement begin!", "This captivating report serves multiple goals. Firstly, it delves into the reproducibility of the groundbreaking paper \"On the regularization of Wasserstein GANs\" (2018). Secondly, we meticulously replicated and emphasized five crucial experiment aspects from the original paper: learning speed, stability, robustness against hyperparameters, estimating the Wasserstein distance, and exploring various sampling methods. Lastly, we offer insights into the reproducibility of the paper's contributions and the resources required, making all source code open to the public for transparency.", "Variational Autoencoders (VAEs) were initially introduced by Kingma & Welling in 2014 as probabilistic generative models that involve approximate Bayesian inference. The concept of $\\beta$-VAEs by Higgins et al. in 2017 revolutionized VAEs by extending their applications beyond generative modeling to areas like representation learning, clustering, and lossy data compression. This was made possible by introducing an objective function that empowers users to balance the information content of the latent representation with the fidelity of the reconstructed data, as demonstrated by Alemi et al. in 2018.\n\nIn our study, we revisit this trade-off between information content and reconstruction accuracy in hierarchical VAEs, which comprise multiple layers of latent variables. We unveil a novel class of inference models that allow for the separate tuning of each layer's contribution to the encoding rate, facilitating more nuanced control. By establishing theoretical bounds on the performance of downstream tasks based on the rates of individual layers, we validate our insights through extensive large-scale experiments.\n\nOur findings offer valuable insights for practitioners, guiding them on navigating the rate-distortion landscape to optimize performance in diverse applications.", "We introduce Graph2Gauss, a novel method for learning versatile node embeddings on large (attributed) graphs. Unlike traditional approaches that represent nodes as point vectors in a low-dimensional space, we model each node as a Gaussian distribution to capture uncertainty about its representation. Our approach excels in tasks like link prediction and node classification, demonstrating strong performance on various graph types including plain/attributed and directed/undirected graphs. We propose an unsupervised method that supports inductive learning, allowing us to generalize to new nodes without additional training. By leveraging both network structure and node attributes, we achieve state-of-the-art results on real-world networks. Moreover, by modeling uncertainty, we can estimate neighborhood diversity and uncover the latent dimensionality of a graph.", "This study investigates using self-ensembling for adapting visual domains. The method is based on the mean teacher variant of temporal ensembling, which has shown excellent results in semi-supervised learning. We make modifications to improve its performance in challenging domain adaptation situations and assess its effectiveness. Our method achieves top performance across different benchmarks, including winning the VISDA-2017 visual domain adaptation challenge. In small image benchmarks, our algorithm surpasses previous methods and approaches the accuracy of supervised classifiers.", "Machine learning classifiers, such as deep neural networks, are susceptible to adversarial examples, which are created by making tiny intentional changes to input data to cause incorrect outputs that are undetectable by humans. The objective of this research is not to propose a specific method but to take theoretical strides towards comprehending adversarial examples fully. By leveraging concepts from topology, our theoretical investigation unveils the main factors behind a classifier ($f_1$) being deceived by an adversarial example and involves an oracle ($f_2$, like human perception) in the analysis. Through an exploration of the topological connection between two (pseudo)metric spaces associated with predictor $f_1$ and oracle $f_2$, we establish conditions that are necessary and sufficient to determine if $f_1$ is consistently robust (strong-robust) against adversarial examples based on $f_2$. Fascinatingly, our theorems reveal that the mere presence of an irrelevant feature can render $f_1$ non-strong-robust, underscoring the importance of feature representation learning in attaining a classifier that is both precise and strongly robust.", "We set up a problem scenario to evaluate how well agents can gather information efficiently. We introduce tasks where agents need to search through a partially-obscured environment to find key pieces of information to achieve goals. By using deep architectures and reinforcement learning techniques, we create agents that can successfully complete these tasks. We guide agent behavior by providing both external and internal rewards. Our experiments show that these agents learn to actively and intelligently search for new information to decrease uncertainty and make use of acquired information.", "We suggest improving neural network language models by adjusting their predictions based on recent history. Our model is a simpler version of memory-enhanced networks, where past hidden activations are stored as memories and accessed using a dot product with the current hidden activation. This method is highly efficient and can work with large memory sizes. We also establish a connection between utilizing external memory in neural networks and cache models used in count-based language models. Our experiments with various language model datasets show that our method outperforms recent memory-enhanced networks by a significant margin.", "GANs are effective deep generative models, based on a two-player minimax game. Our novel algorithm repeats density ratio estimation and f-divergence minimization, offering a new perspective on GANs and incorporating insights from research on density ratio estimation, such as stability of divergence and usefulness of relative density ratio.", "We introduce an innovative framework for creating pop music using a hierarchical Recurrent Neural Network. The hierarchy's layers are designed to reflect our understanding of pop music composition: lower layers focus on melody generation, while higher levels handle drums and chords. Human studies show a clear preference for our music over Google's approach. Our framework also powers neural dancing and karaoke, along with neural story singing.", "We examine the eigenvalues of the Hessian matrix associated with a loss function both pre- and post-training. The distribution of eigenvalues appears to exhibit a distinct duality, comprising a central cluster that converges toward zero, alongside peripheral outliers that diverge significantly from zero. Our findings offer empirical substantiation for the central cluster, revealing insights into the extent of over-parametrization within the system, as well as for the outliers, whose positioning is shown to be contingent upon the input data.", "This paper introduces a novel feature extraction method for program execution logs. We automatically extract intricate patterns from a program's behavior graph and embed them into a continuous space using an autoencoder. The proposed features are tested on real-world malicious software detection and reveal interpretable structures within the pattern parts' space.", "We tested the FlyHash model, a sparse neural network inspired by insects, against non-sparse models in a navigation task. The task involves using visual inputs to steer by comparing them to stored memories along a training route. Our findings show that the FlyHash model is more efficient than other models, particularly in terms of data encoding.", "Engaging reformulation:\n\"In the world of peer review, reviewers are often tasked with scoring papers, which are then pivotal in decision-making by Area Chairs or Program Chairs. Yet, relying solely on these scores can be limiting due to human cognitive abilities. This leads to a common issue of tied scores, where valuable information is lost. To overcome this, conferences are now asking reviewers to also provide rankings of the papers they evaluate. But two challenges arise: the lack of a standardized way to utilize this ranking data and the absence of tools to incorporate it effectively, resulting in a less efficient peer-review process. Our innovative approach integrates rankings with scores, delivering updated scores that address these challenges. This method ensures consistency in how rankings are blended with scores for all papers, minimizing arbitrariness and seamlessly integrating with existing interfaces and workflows. Through empirical evaluation on synthetic and real datasets from ICLR 2017, we demonstrate a significant reduction in error rates, offering a promising solution for enhancing the peer-review process.\"", "Numerous recent studies have delved into the intriguing world of status bias within the rigorous peer-review process of academic journals and conferences. This article embarks on an exciting journey to uncover the fascinating link between author metadata and the final decisions (Accept/Reject) made by area chairs. Our quest takes us through a treasure trove of 5,313 borderline submissions to the renowned International Conference on Learning Representations (ICLR) spanning from 2017 to 2022.\n\nWith the precision of a skilled investigator, we meticulously outline the elements of our cause-and-effect analysis. We explore the treatment and its timing, pre-treatment variables, potential outcomes, and the intriguing causal null hypothesis, all within the rich tapestry of textual data and under the esteemed guidance of Neyman and Rubin's potential outcomes (PO) framework.\n\nAmidst our scholarly expedition, we unearth intriguing hints that author metadata may indeed influence the fate of academic articles. Furthermore, our discoveries reveal a captivating revelation \u2013 borderline articles hailing from prestigious institutions in the top echelons of academia (top-30% or top-20%) seem to face a less favorable stance from area chairs compared to their equally matched counterparts.\n\nThese remarkable findings stand firm across two distinct matched designs, painting a vivid picture of the landscape where odds ratios of 0.82 [95% CI: 0.67 to 1.00] in the first design and 0.83 [95% CI: 0.64 to 1.07] in a reinforced design eloquently signify our triumph.\n\nAs we unravel the complexities of our results, we delve into the intricate dance between study units and the myriad agents at play within the peer-review system. It is a tale of interactions, revelations, and insights that shed light on the compelling dynamics that shape the scholarly world we inhabit.", "We introduce a variational method inspired by Tishby et al.'s information bottleneck (1999). This approach involves using a neural network to parameterize the information bottleneck model and benefits from the reparameterization trick for effective training. Referred to as \"Deep Variational Information Bottleneck\" (Deep VIB), this method demonstrates superior generalization and robustness to adversarial attacks compared to models trained with alternative regularization techniques.", "Attention networks have proven to be effective for embedding categorical inference within deep neural networks. However, to model richer structural dependencies without losing end-to-end training, we experiment with incorporating graphical models encoded with richer structural distributions into deep networks. This work introduces structured attention networks as extensions of the basic attention procedure, enabling attention beyond the traditional soft-selection approach. We explore two classes of structured attention networks: linear-chain conditional random fields and graph-based parsing models, discussing their practical implementation as neural network layers. Experiments reveal that this approach effectively incorporates structural biases, with structured attention networks outperforming baseline models across various tasks like tree transduction, neural machine translation, question answering, and natural language inference. Additionally, models trained this way learn unsupervised hidden representations that generalize simple attention mechanisms.", "We propose using a group of specialized experts based on the confusion matrix. We noticed that in certain cases, when faced with tricky situations, the labels tend to be assigned to a few wrong classes. This suggests that a team of specialists could do a better job at spotting and rejecting misleading instances by having varying opinions when dealing with adversaries. Our experimental results support this idea by showing that this approach can enhance the system's resilience to tricky examples. Instead of solely focusing on classifying them correctly, we aim to improve the system by rejecting such cases.", "In this scholarly article, we introduce the Neural Phrase-based Machine Translation (NPMT) framework. Our approach intricately incorporates phrase structures in the generated sequences by leveraging Sleep-WAke Networks (SWAN), a novel segmentation-based sequence modeling technique. To address the strict requirement of monotonic alignment in SWAN, a new layer is introduced to facilitate (soft) local reordering of input sequences. Differing from conventional neural machine translation (NMT) methods, NPMT eschews attention-based decoding mechanisms. Instead, it directly yields phrases in a systematic manner, allowing for linear-time decoding. Empirical results from our conducted experiments demonstrate that NPMT outperforms existing NMT models on the IWSLT 2014 German-English/English-German and IWSLT 2015 English-Vietnamese machine translation tasks. Additionally, our findings signify that NPMT generates coherent and meaningful phrases in the target languages.", "Introducing LR-GAN: a cutting-edge adversarial image generator that goes beyond the norm by incorporating scene structure and context. Unlike its predecessors, this innovative GAN has the ability to intricately craft backgrounds and foregrounds separately and recursively, expertly weaving them together in a way that captures the essence of a natural image. Through its unsupervised training, LR-GAN refines the generation of appearance, shape, and pose for each foreground element with seamless integration. The comprehensive experiments reveal LR-GAN's knack for producing lifelike images with objects that are notably more human recognizable compared to conventional models like DCGAN.", "We present an elegant framework in which an agent can autonomously acquire knowledge about its environment. Our framework introduces a dynamic interaction between two autonomous entities, Alice and Bob, as they engage in a collaborative learning process. Specifically, Alice initiates a task for Bob to complete, prompting him to respond by executing the required actions. Our focus in this study lies on two distinct types of environments: those that are nearly reversible, and those amenable to reset. To convey the task, Alice executes a sequence of actions that Bob must either reverse or replicate. Through a carefully designed reward system, Alice and Bob jointly shape a learning curriculum that facilitates unsupervised training of the agent. Leveraging this unsupervised training method in Bob's reinforcement learning applications within the environment, we observe a notable decrease in the required supervised episodes for learning, sometimes resulting in superior reward convergence.", "Maximum entropy modeling serves as a versatile and widely embraced approach for constructing statistical models when possessing only partial information. Instead of following the customary path of directly optimizing the continuous density, this study focuses on acquiring a smooth and reversible transformation that aligns a basic distribution with the desired maximum entropy distribution. This task is particularly challenging as the optimization target (entropy) is contingent on the density itself. Leveraging advancements in normalizing flow networks, the researchers outline a strategy for reformulating the maximum entropy conundrum into a finite-dimensional, constrained optimization issue. This is tackled through the amalgamation of stochastic optimization with the augmented Lagrangian method. The efficacy of the proposed method is demonstrated through simulation findings, while real-world applications in finance and computer vision underscore the adaptability and precision of maximum entropy flow networks.", "With machine learning breaking new ground by conquering challenging tasks daily, the vision of achieving general AI is coming within reach. Yet, the current research primarily emphasizes specific applications like image classification and machine translation. This trend largely stems from the difficulty in objectively gauging advancements towards comprehensive machine intelligence. To address this issue, we introduce a clear set of objectives for general AI and a testing framework to assess machine performance against these objectives, streamlining the process.", "Neural networks that compute over graph structures are suitable for problems in various domains like natural language and cheminformatics. However, these networks do not directly support batched training or inference due to the varied shape and size of the computation graph for each input. Implementing them in popular static data-flow graph-based deep learning libraries is also challenging. We introduce dynamic batching, a technique that enables batching operations across different input graphs and nodes within a single input graph. This technique allows us to create static graphs using popular libraries that mimic dynamic computation graphs of any shape and size. We also present a high-level library of compositional blocks to simplify the creation of dynamic graph models and demonstrate concise batch-wise parallel implementations for various models.", "Deep learning models in natural language processing are effective but often operate as black boxes, providing little insight into their decision-making process. This paper introduces a new method for tracking the importance of inputs to Long Short Term Memory networks (LSTMs) in producing outputs. We identify significant word patterns to distill state-of-the-art LSTMs on sentiment analysis and question answering into key phrases. These phrases are then validated quantitatively by constructing a rule-based classifier that closely mimics the LSTM's output.", "In recent years, deep reinforcement learning has accomplished impressive feats. However, challenges persist with tasks that offer sparse rewards or have long horizons. To address these issues, we propose a general framework that involves learning useful skills in a pre-training environment before applying them to expedite learning in subsequent tasks. Our method combines aspects of intrinsic motivation and hierarchical methods by guiding the learning of valuable skills through a single proxy reward that demands minimal domain knowledge of the tasks. This leads to the training of a high-level policy on these skills, enhancing exploration and enabling handling of sparse rewards. To efficiently pre-train diverse skills, we utilize Stochastic Neural Networks with an information-theoretic regularizer. Our experiments demonstrate that this approach is effective in learning a broad range of understandable skills in a resource-efficient manner and significantly improves learning performance consistently across various subsequent tasks.", "In recent years, deep generative models, such as Generative Adversarial Networks (GANs) and Variational Autoencoders (VAEs), have shown significant success. While traditionally viewed as separate paradigms, GANs and VAEs have been the focus of extensive research efforts. This paper seeks to establish formal connections between GANs and VAEs by introducing a new formulation. We consider sample generation in GANs as a form of posterior inference and demonstrate that both GANs and VAEs aim to minimize KL divergences in their respective posterior and inference distributions, albeit in opposite directions. This approach extends the two learning phases of the classic wake-sleep algorithm. By adopting this unified perspective, we are able to analyze various model variants effectively and transfer techniques across different research avenues in a systematic manner. For instance, we integrate the importance weighting method from VAE literature to enhance GAN learning, and introduce an adversarial mechanism to VAEs that utilizes generated samples. Through experiments, we demonstrate the general applicability and effectiveness of these transferred techniques.", "We address the issue of identifying out-of-distribution images in neural networks using ODIN, a straightforward yet powerful technique that does not necessitate modifications to the pre-trained neural network. By leveraging temperature scaling and introducing minor perturbations to the input, we achieve a clear separation of softmax scores for in-distribution and out-of-distribution images, enhancing detection capabilities significantly. Through various experiments, we demonstrate that ODIN is versatile across different network architectures and datasets, consistently outperforming the baseline method by a significant margin and setting a new performance benchmark. For instance, in the case of the DenseNet model on CIFAR-10, ODIN dramatically decreases the false positive rate from 34.7% to 4.3% while maintaining a 95% true positive rate.", "A framework has been introduced for unsupervised learning of representations by leveraging the infomax principle with large-scale neural populations. Through the utilization of an asymptotic approximation of Shannon's mutual information, it has been shown that an effective initial estimation of the global information-theoretic optimum can be achieved by employing a hierarchical infomax approach. Following this initial stage, a proficient algorithm, utilizing gradient descent of the final objective function, has been suggested to acquire representations from input datasets, adapting to complete, overcomplete, and undercomplete bases. Through numerical experiments, it has been evidenced that our method is both robust and highly efficient in extracting prominent features from input datasets. In comparison to prevailing methods, our algorithm stands out due to its noteworthy speed in training and the overall resilience of unsupervised representation learning. Additionally, the proposed method can be readily expanded to encompass supervised or unsupervised models for the training of deep structural networks.", "Recurrent Neural Networks (RNNs) are well-known for their excellent performance in sequence modeling tasks. However, training RNNs on long sequences can present challenges such as slow inference speed, vanishing gradients, and difficulty in capturing long term dependencies. In the context of backpropagation through time, these challenges are often linked to the large, sequential computational graph that arises from unrolling the RNN over time. To address these issues, we propose the Skip RNN model, which extends traditional RNNs by learning to skip state updates, thereby reducing the effective size of the computational graph. The model can also be trained to minimize the number of state updates through a budget constraint. Our evaluations on various tasks demonstrate that the Skip RNN model can decrease the required number of RNN updates while maintaining or even enhancing the performance compared to baseline RNN models. For those interested, the source code is available at https://imatge-upc.github.io/skiprnn-2017-telecombcn/.", "Restart methods are commonly used in optimization without using gradient information to handle complex functions with multiple peaks. Partial restart methods are becoming popular in optimization with gradient information to speed up convergence in methods that move faster through difficult functions. In this research, we introduce a straightforward restart approach for stochastic gradient descent to enhance its performance during the training of deep neural networks, regardless of when it is stopped. We test its effectiveness on CIFAR-10 and CIFAR-100 datasets and report improved performance of 3.14% and 16.21% accuracy, respectively, setting new records. Additionally, we show its benefits on an EEG dataset and a downsized version of the ImageNet dataset. The code used is accessible at https://github.com/loshchil/SGDR.", "Policy gradient methods have demonstrated considerable success in addressing complex reinforcement learning tasks. Nevertheless, they frequently encounter challenges associated with high variance in policy gradient estimation, resulting in suboptimal sample efficiency during the training process. This study introduces a novel control variate approach to mitigate variance issues in policy gradient methods. Drawing inspiration from Stein's identity, our method expands upon existing control variate techniques applied in REINFORCE and advantage actor-critic strategies by incorporating versatile action-dependent baseline functions. Empirical findings illustrate the substantial enhancement in sample efficiency achieved by our approach relative to contemporary policy gradient methodologies.", "Skip connections have revolutionized the training of deep neural networks, making it possible to build networks with numerous layers. They have now become a crucial element in a wide range of neural architectures. While the exact reasons behind their effectiveness remain a mystery, we propose a fresh perspective on why skip connections are so beneficial in training very deep networks.\n\nThe challenge of training deep networks stems from the singularities caused by the inherent non-identifiability of the model. These singularities, identified in previous studies, include overlap singularities resulting from the permutation symmetry of nodes, elimination singularities from the deactivation of nodes, and singularities arising from node linear dependence. These singularities create degenerate regions in the loss landscape, hindering the learning process.\n\nWe posit that skip connections mitigate these singularities by disrupting the permutation symmetry of nodes, reducing the likelihood of node deactivation, and decreasing node linear dependence. Additionally, by initializing the network with skip connections, we can steer the network away from these problematic singularities, reshaping the landscape to facilitate smoother learning. This hypothesis is validated through simplified models and experiments with deep networks trained on real-world datasets.", "We endeavored to replicate the findings of the research paper \"Natural Language Inference across Interaction Space\" which was presented at the ICLR 2018 conference, forming a part of the ICLR 2018 Reproducibility Challenge. Initially, we embarked on creating our own implementation of the network, only later finding out that the code was readily available. Our version of the model was put to the test on the Stanford NLI dataset, achieving an impressive accuracy of 86.38% on the test set, while the original paper reported 88.0% accuracy. The key disparities seem to stem from discrepancies in optimizers and the methodology employed for model selection.", "We have effectively applied the \"Learn to Pay Attention\" attention mechanism model in convolutional neural networks, and have achieved the same outcomes as the original paper in image classification and fine-grained recognition categories.", "Learning universal distributed representations of sentences is a crucial objective in the field of natural language processing. Our proposed technique involves encoding the suffixes of word sequences in sentences and leveraging the Stanford Natural Language Inference (SNLI) dataset for training. Through evaluation on the SentEval benchmark, we showcase the efficiency of our method, which outperforms existing approaches across various transfer tasks.", "In modern neural models, advanced features are created by leveraging polynomial functions of existing ones to enhance representations. For instance, in our exploration utilizing the natural language inference task, we delved into the effectiveness of incorporating scaled polynomials of degree 2 and higher as matching features. Notably, our results revealed that scaling degree 2 features significantly boosts performance, leading to a remarkable 5% reduction in classification error for the most successful models.", "We introduce a generalization bound for feedforward neural networks based on the product of the spectral norm of the layers and the Frobenius norm of the weights. This generalization bound is obtained through a PAC-Bayes analysis.", "In our research, we delve into the Batch Normalization technique from a fresh perspective by introducing its probabilistic interpretation. We present a probabilistic model that highlights how Batch Normalization optimizes the lower bound of its marginalized log-likelihood. Our proposed probabilistic framework guides the development of a training algorithm that remains consistent across training and testing phases. Despite the efficiency of our approach, computational challenges arise during inference stages. To address this issue and enhance computational efficiency, we introduce Stochastic Batch Normalization as a practical approximation of the proper inference process. This method not only streamlines memory usage and computational demands but also enables a scalable uncertainty estimation approach. Through rigorous experimentation on well-known architectures such as VGG-like and ResNets for MNIST and CIFAR-10 datasets, we showcase the effectiveness of Stochastic Batch Normalization in enhancing model performance.", "Discover a groundbreaking revelation in the realm of deep convolutional networks! Contrary to popular belief, you'll be amazed to learn that losing information isn't the key to their success. Enter the realm of i-RevNet, a revolutionary network that defies traditional norms by retaining all information through a cascade of homeomorphic layers. Unravel the mystery of invertibility and witness the magic of progressive contraction and linear separation. Embark on a journey through natural image representations and shed light on the enigma of i-RevNet's learned model.", "In this paper, we explore the effectiveness of deep latent variable models, particularly the deep information bottleneck model. We highlight its limitations and introduce an enhanced model that overcomes these challenges. Our approach involves implementing a copula transformation, which restores the information bottleneck method's key invariance properties. This transformation enables the disentanglement of features within the latent space and promotes sparsity. Through experimentation on artificial and real data, we demonstrate the performance of our proposed method.", "We propose a modified version of the MAC model (Hudson and Manning, ICLR 2018) that utilizes simplified equations to maintain high accuracy and faster training speed. Evaluation on CLEVR and CoGenT demonstrates a significant 15-point increase in accuracy through transfer learning with fine-tuning, achieving state-of-the-art performance. Additionally, our study highlights that incorrect fine-tuning can diminish the model's accuracy.", "Adaptive Computation Time for Recurrent Neural Networks (ACT) is a promising architecture that can adjust the amount of computation needed for different tasks. ACT can look at each input sample multiple times and learn how many repetitions are necessary. In this study, we compare ACT with Repeat-RNN, a new architecture that repeats each sample a set number of times. Surprisingly, we found that Repeat-RNN performs just as well as ACT in the tasks we tested. You can find the source code in TensorFlow and PyTorch at https://imatge-upc.github.io/danifojo-2018-repeatrnn/", "Generative adversarial networks (GANs) have the ability to represent the intricate patterns found in real-world data, making them promising for spotting anomalies. Despite this potential, only a limited number of studies have delved into using GANs for anomaly detection. By utilizing advanced GAN models, we excel in detecting anomalies on image and network intrusion datasets and outperform the only known GAN-based method by a significant margin in terms of speed during testing.", "The Natural Language Inference (NLI) task involves determining how two sentences are related to each other. We have developed the Interactive Inference Network (IIN), a new type of neural network that can understand sentence pairs by extracting meaning in a step-by-step way. Our research shows that paying attention to how sentence parts interact helps in understanding the relationship between sentences. This approach, known as the Densely Interactive Inference Network (DIIN), has shown excellent results on large datasets. In fact, DIIN reduces errors by more than 20% compared to the best-known system when tested on the challenging Multi-Genre NLI (MultiNLI) dataset.", "The deployment of neural networks in real-world, safety-critical systems faces a significant challenge due to adversarial examples \u2013 perturbed inputs that can cause misclassification. Despite numerous techniques aimed at improving robustness, many have quickly succumbed to new attacks. For instance, more than half of the defenses introduced at ICLR 2018 have already been breached. Our solution to this dilemma lies in formal verification methods. We present a method for generating provably minimal adversarial examples \u2013 ensuring that the distortions are minimized. By applying this technique, we showcase the effectiveness of adversarial retraining, a recent defense proposal from ICLR, in increasing the distortion required for crafting adversarial examples by a factor of 4.2.", "Sure! Here is a reworded version:\n\nDeep neural networks (DNNs) have shown impressive predictive abilities by understanding complex, non-linear connections between variables. However, their lack of transparency has led them to be labeled as black boxes, limiting their applications. To address this issue, we introduce hierarchical interpretations through a method called agglomerative contextual decomposition (ACD). ACD explains DNN predictions by providing a hierarchy of input features and their contributions to the final prediction. This hierarchy helps identify predictive feature clusters learned by the DNN. Our experiments using Stanford Sentiment Treebank and ImageNet datasets demonstrate that ACD can diagnose incorrect predictions and detect dataset biases effectively. Human experiments show that ACD enables users to identify the more accurate DNN among two choices and instills greater confidence in a DNN's outputs. ACD's hierarchy is also shown to be resilient against adversarial perturbations, focusing on essential input aspects while ignoring noise.", "In our latest project, we tackle the fascinating challenge of transforming musical timbre. Imagine being able to change the timbre of a sound sample from one instrument to match another, without altering its pitch, rhythm, or volume. This process involves a delicate balance of art and science, inspired by image-based style transfer techniques applied to audio signals.\n\nEnter TimbreTron - our groundbreaking approach to musical timbre transfer. By leveraging cutting-edge technology, we use an \"image\" domain style transfer method on the time-frequency representation of the audio, creating a seamless transition between instruments. The magic continues as we generate a high-fidelity audio waveform using a conditional WaveNet synthesizer.\n\nOur research reveals that the Constant Q Transform (CQT) representation is key to our success, allowing us to maintain pitch consistency throughout the process. Through rigorous human assessments, we have confirmed that TimbreTron achieves remarkable results, effectively transferring timbre while preserving the essence of the original musical composition, whether it's a solo melody or a complex harmony. Join us on this sonic journey where innovation meets musicality!", "We're diving into word-level language modeling and exploring how we can blend short-term representations with medium-term ones in a language model. Building on recent experiments using dynamically changing weights in language models, we're framing the language modeling challenge as an online learning adventure. In this setup, a meta-learner gets busy training to fine-tune our language model's weights continually through gradient descent.", "Generative Adversarial Networks (GANs) are potent generative models capable of representing the manifold of natural images. This feature is employed to execute manifold regularization through an approximation of the Laplacian norm using a Monte Carlo method that can be readily computed within the GAN framework. By integrating this approach into the feature-matching GAN proposed in Improved GAN, we attain cutting-edge outcomes for semi-supervised learning based on GANs using the CIFAR-10 dataset. Notably, our method offers a notable advantage in terms of implementation simplicity compared to alternative approaches.", "We have uncovered a fascinating class of over-parameterized deep neural networks that defy the odds by possessing a unique property - they have no bad local valleys! This means that you can traverse through continuous paths in their parameter space, continuously decreasing the cross-entropy loss until it nearly reaches zero. Consequently, these networks are free from sub-optimal strict local minima. How incredible is that?", "Visual Question Answering (VQA) models have STRUGGLED with COUNTING objects in natural images. A FUNDAMENTAL PROBLEM, identified as SOFT ATTENTION in these models, is the culprit. To SOLVE this, we propose a neural network component for ROBUST COUNTING from object proposals. Our EXPERIMENTS on a toy task demonstrate the EFFECTIVENESS of this approach, leading to STATE-OF-THE-ART ACCURACY on the number category of the VQA v2 dataset. Surprisingly, our SINGLE MODEL OUTPERFORMS ensemble models. Our component offers a 6.6% IMPROVEMENT over a STRONG baseline in counting.", "A significant challenge in the examination of generative adversarial networks lies in the volatility of their training process. Within this manuscript, we present a groundbreaking weight normalization approach known as spectral normalization designed to enhance the stability of the discriminator's training. This innovative normalization method is lightweight computationally and seamlessly integrates into current frameworks. Through rigorous testing on the CIFAR10, STL-10, and ILSVRC2012 datasets, we verified experimentally that using spectrally normalized GANs (SN-GANs) enables the generation of images that are superior to or on par with those produced by preceding training stabilization methods.", "Embedding graph nodes into a vector space enables the utilization of machine learning for tasks such as predicting node classes. However, it is noteworthy that the study of node embedding algorithms is not as well-developed compared to the natural language processing field, largely due to the heterogeneous and complex nature of graphs. In this study, we analyze the efficacy of various node embedding algorithms in relation to graph centrality metrics that capture the diversity of graphs. Through structured experimentation involving four node embedding algorithms, four to five graph centrality metrics, and six distinct datasets, we have obtained empirical insights into the performance of node embedding algorithms. These findings serve as a foundational framework for further exploration and research in this domain.", "Introducing a groundbreaking dataset of logical entailments to evaluate models' capacity in capturing and leveraging logical structures for an entailment prediction task. We put various architectures, common in sequence-processing, up against each other, including a novel model class - PossibleWorldNets, which processes entailment through a \"convolution over possible worlds\". Findings reveal that while convolutional networks possess an unsuitable inductive bias for these tasks compared to LSTM RNNs, tree-structured neural networks excel over LSTM RNNs owing to their superior syntax exploitation. Notably, PossibleWorldNets surpass all benchmarks, showcasing exceptional performance.", "Neural network pruning methods can significantly reduce the parameter counts of trained networks, which decreases storage requirements and enhances computational performance during inference without compromising accuracy. However, sparse architectures resulting from pruning are often challenging to train initially, which could also enhance training performance. Our research shows that a typical pruning technique naturally reveals subnetworks that were effectively trainable due to their initializations. Based on these findings, we introduce the \"lottery ticket hypothesis,\" suggesting that within dense, randomly-initialized, feed-forward networks are subnetworks (\"winning tickets\") that, when trained independently, achieve test accuracy similar to the original network in a comparable number of iterations. These winning tickets benefit from fortuitous initializations, with connections possessing initial weights conducive to effective training. We propose an algorithm to identify winning tickets and present experimental results that confirm the lottery ticket hypothesis and the significance of these fortunate initializations. Our experiments consistently identify winning tickets that are less than 10-20% the size of various fully-connected and convolutional feed-forward architectures for MNIST and CIFAR10. Networks corresponding to these winning tickets, larger than the mentioned size range, outperform the original network by learning faster and achieving higher test accuracy.", "The singular values of the linear transformation linked with a standard 2D multi-channel convolutional layer are identified to facilitate efficient computation. This identification further paves the way for developing an algorithm to project a convolutional layer onto an operator-norm ball. It has been demonstrated that this serves as a valuable regularizer, as evidenced by its ability to reduce the test error of a deep residual network utilizing batch normalization on CIFAR-10 from 6.2\\% to 5.3\\%.", "Despite the empirical success of deep and locally connected nonlinear networks like deep convolutional neural networks (DCNN), understanding their theoretical properties remains a challenging task. In this paper, we introduce a new theoretical framework designed for these networks using ReLU nonlinearity. This framework explicitly defines the data distribution, promotes disentangled representations, and integrates well with popular regularization methods such as Batch Norm. By leveraging a teacher-student approach, we extend the student's forward and backward propagation within the teacher's computational graph. Importantly, our model avoids making unrealistic assumptions, such as Gaussian inputs or activation independence. Our proposed framework offers a means to analyze various practical issues theoretically, including overfitting, generalization, and disentangled representations within deep networks.", "We introduce a Neural Program Search algorithm, which creates programs from natural language descriptions and a few input/output examples. This algorithm merges techniques from Deep Learning and Program Synthesis areas, forming a specialized domain-specific language (DSL) and a powerful search algorithm guided by a Seq2Tree model. Additionally, to assess the effectiveness of the approach, we offer a semi-synthetic dataset containing descriptions, test examples, and corresponding programs. Our results demonstrate a substantial improvement over a baseline sequence-to-sequence model with attention.", "State-of-the-art neural machine translation systems vary in their structures but typically include the crucial feature of Attention. While many attention methods focus on individual tokens and overlook the significance of phrasal alignments, important for traditional phrase-based machine translation success, our study introduces innovative phrase-based attention techniques. These methods consider n-grams of tokens as attention units, enhancing the Transformer network. Our experiments show that incorporating our phrase-based attention leads to performance boosts of 1.3 BLEU for English-to-German and 0.5 BLEU for German-to-English translations when evaluated on the WMT newstest2014 dataset using WMT'16 training data.", "We address the challenge of learning distributed representations of edits using a combination of a \"neural editor\" and an \"edit encoder\". Our models effectively capture key information of edits and can be applied to new inputs. We conduct experiments on natural language and source code edit data, with promising results indicating that our neural network models successfully capture the structure and meaning of edits. We encourage other researchers to explore this task and data source further.", "We introduce a principled kernel learning approach based on Fourier-analytic properties of translation-invariant or rotation-invariant kernels. Our method generates a series of feature maps to enhance the SVM margin iteratively. We offer rigorous guarantees on optimality and generalization, viewing our algorithm as a dynamic equilibrium-finding process in a specific two-player min-max game. Experiments on synthetic and real datasets show scalability and consistent enhancements over comparable random features methods.", "This paper introduces Variational Continual Learning (VCL), a sophisticated and versatile framework for continual learning that integrates online variational inference (VI) and recent advancements in Monte Carlo VI tailored for neural networks. The framework exhibits the ability to effectively train deep discriminative and deep generative models in intricate continual learning scenarios characterized by evolving existing tasks and emerging new tasks. Empirical findings demonstrate that VCL surpasses existing state-of-the-art continual learning approaches across various tasks, mitigating catastrophic forgetting through fully autonomous means.", "This report serves a number of exciting purposes! To begin with, we're on a mission to explore the reproducibility standards of the enlightening paper titled \"On the regularization of Wasserstein GANs (2018)\". We dive deep into five key experiment facets highlighted in the paper: learning speed, stability, resilience to hyperparameters, accurate estimation of Wasserstein distance, and the exploration of diverse sampling methods. Our ultimate goal is to unveil the parts of this research that can be successfully replicated, all while considering the resources involved. The best part? All the source code needed for reproduction is freely available to the public! Let's embark on this fascinating journey together.", "Here is the revised text:\n\nThis paper introduces a novel method for extracting features from program execution logs. Initially, intricate patterns are automatically extracted from a program's behavior graph. Subsequently, these patterns are transformed into a continuous space through the training of an autoencoder. The effectiveness of the proposed features is assessed in the context of detecting real-world malicious software. Additionally, it is observed that the embedding space reveals intelligible structures within the pattern components.", "We present a novel neural probabilistic model utilizing variational autoencoder architecture. This model offers the flexibility to be conditioned on any chosen subset of observed features, enabling simultaneous sampling of the remaining features. The features can encompass both real-valued and categorical data. The model is trained using stochastic variational Bayes method. Results from experiments on synthetic data, feature imputation, and image inpainting tasks demonstrate the success of our approach in producing diverse and effective samples.", "Variational Autoencoders (VAEs) were initially proposed by Kingma & Welling (2014) as probabilistic generative models that enable approximate Bayesian inference. The concept of $\\beta$-VAEs (Higgins et al., 2017) expanded the scope of VAEs beyond generative modeling to encompass various application domains such as representation learning, clustering, and lossy data compression. This extension introduced an objective function that empowers practitioners to balance the trade-off between the information content (bit rate) of the latent representation and the fidelity of the reconstructed data (Alemi et al., 2018). \n\nThis study reexamines the rate/distortion trade-off within the framework of hierarchical VAEs, which involve multiple layers of latent variables. We introduce a broad class of inference models that enable the division of the overall rate into individual layer contributions, providing the flexibility to adjust each layer's rate independently. By establishing theoretical performance bounds for downstream tasks based on the rates of individual layers, we conduct extensive large-scale experiments to validate our theoretical insights. Our findings offer practical guidance for practitioners seeking to optimize the rate-space for specific applications.", "Studying the subspaces of adversarial examples is crucial for assessing the resilience of deep neural networks (DNNs) against adversarial perturbations. A recent study by Ma et al. (ICLR 2018) introduced the concept of using the local intrinsic dimensionality (LID) within the hidden layers of DNNs to examine these adversarial subspaces. Their research showcased the applicability of LID in delineating the adversarial subspaces related to various attack techniques, such as the Carlini and Wagner's (C&W) attack and the fast gradient sign attack.\n\nIn this particular study, experimental investigations on MNIST and CIFAR-10 datasets were conducted to delve into new dimensions beyond the traditional LID analysis, highlighting the challenges in using LID to fully characterize the corresponding adversarial subspaces. The study identified two key limitations: (i) the sensitivity of LID performance to the confidence levels set by an attacking algorithm, with ensemble learning on adversarial examples at different confidence levels yielding unexpectedly weak results, and (ii) the inadequacy of LID in delineating adversarial subspaces when the attacks originate from a different DNN model, as noted in the context of black-box transfer attacks.\n\nThese insightful findings collectively underscore the restricted capacity of LID in effectively characterizing the subspaces associated with adversarial examples, shedding light on the overarching significance of further research in this domain.", "GANs are known for producing appealing samples but are difficult to train. Current approaches focus on proposing new formulations of the GAN objective, with little attention given to optimization methods for adversarial training. Our work shifts the focus by applying variational inequality framework to GAN optimization problems. Drawing from mathematical programming literature, we challenge misconceptions about saddle point optimization difficulties and introduce techniques tailored for training GANs, such as averaging, extrapolation, and a computationally cheaper variant called extrapolation from the past, to stochastic gradient descent (SGD) and Adam.", "Recently, groundbreaking advances have been made in neural message passing algorithms for semi-supervised classification on graphs. Despite their success, these methods have been limited by their consideration of only nodes within a few propagation steps, making it challenging to extend the neighborhood size effectively. In this study, we introduce a novel approach that exploits the connection between graph convolutional networks (GCN) and PageRank to enhance the propagation scheme, utilizing personalized PageRank. This leads to the development of a streamlined model, personalized propagation of neural predictions (PPNP), alongside its efficient approximation, APPNP. Notably, our model offers training times comparable to or faster than existing models, with an equivalent or reduced number of parameters. By enabling a large, adjustable neighborhood for classification, it seamlessly integrates with any neural network. Extensive evaluations demonstrate that our model surpasses several state-of-the-art methods in semi-supervised classification, marking a significant milestone in GCN-like model research. Our implementation is readily accessible online for further exploration.", "We have identified disguised gradients, a type of gradient hiding, as a phenomenon that creates a false sense of safety in protections against adversarial instances. Although protections that produce disguised gradients seem to block iterative optimization-driven attacks, we have observed that safeguards based on this feature can still be bypassed. We detail typical behaviors of safeguards displaying this feature and, for each of the three forms of disguised gradients we have identified, we craft offensive strategies to surpass them. In an investigation, focusing on non-certified white-box-secure protections at ICLR 2018, we note that disguised gradients are prevalent, with 7 out of 9 defenses counting on them. Our new strategies effectively bypass 6 defenses completely, and 1 partially, in the initially considered threat model of each paper.", "Our groundbreaking approach, Graph2Gauss, revolutionizes network analysis by efficiently learning versatile node embeddings on large-scale graphs. By representing nodes as Gaussian distributions instead of typical point vectors, we capture uncertainty and improve performance in tasks such as link prediction and node classification. This method excels in handling diverse types of graphs and inductive learning scenarios, offering superior generalization to unseen nodes without the need for further training. Through personalized ranking formulation based on node distances, we leverage network structure to achieve outstanding results, surpassing state-of-the-art methods on various tasks. Our experiments on real-world networks highlight the exceptional performance of Graph2Gauss, showcasing its capability to model uncertainty, estimate neighborhood diversity, and reveal the latent dimensionality of graphs.", "Convolutional Neural Networks (CNNs) have become the go-to approach for tackling learning tasks concerning 2D flat images. Nevertheless, various contemporary challenges have surfaced, necessitating models capable of analyzing spherical images. Scenarios include all-encompassing vision for drones, robots, and self-driving vehicles, molecular regression dilemmas, and worldwide weather and climate simulations. Simply employing convolutional networks on a flat projection of the spherical signal is doomed to fail due to the varying distortions caused by such a projection, rendering translational weight sharing ineffective. In this manuscript, we lay out the foundational elements for architecting spherical CNNs. We present a formulation for the spherical cross-correlation that is both eloquent and rotation-equivalent. The spherical correlation adheres to a general Fourier principle, empowering us to efficiently compute it using a general (non-commutative) Fast Fourier Transform (FFT) technique. We showcase the computational efficiency, numerical preciseness, and efficiency of spherical CNNs in the realm of 3D model identification and atomization energy regression.", "This study highlights the utilization of natural language processing (NLP) techniques for addressing classification challenges in cheminformatics. The integration of these distinct fields is demonstrated through the analysis of the conventional textual representation of chemical compounds, known as Simplified Molecular Input Line Entry System (SMILES). The research focuses on activity prediction against a specific target protein, a pivotal aspect of the computer-aided drug design process. Experimental results indicate that the application of NLP methods not only surpasses current state-of-the-art outcomes achieved through manual feature engineering but also offers valuable structural insights regarding the decision-making process.", "Utilizing Computer Vision and Deep Learning technologies in Agriculture is intended to enhance the quality and productivity of harvests for farmers. The sorting of fruits and vegetables plays a crucial role in postharvest processes and market viability. Apples, in particular, are prone to various defects that may arise during harvesting or post-harvest stages. This study seeks to support farmers in post-harvest management by investigating the potential of contemporary computer vision and deep learning approaches, like YOLOv3 (Redmon & Farhadi (2018)), in identifying healthy apples among those with defects.", "We introduce two straightforward methods to decrease the number of parameters and speed up the training of extensive Long Short-Term Memory (LSTM) networks. The first method involves \"matrix factorization by design,\" where the LSTM matrix is broken down into the product of two smaller matrices. The second method is the partitioning of the LSTM matrix, its inputs, and states into independent groups. Both techniques enable the training of large LSTM networks much faster, nearing state-of-the-art perplexity levels, while utilizing notably fewer RNN parameters.", "Modern deep reading comprehension models are mostly built on recurrent neural networks, which are inherently sequential and well-suited for language processing. However, their lack of parallelization within instances can hinder deployment in time-sensitive scenarios, especially with longer texts. In this study, we propose a convolutional architecture as a viable alternative to traditional recurrent models. By employing straightforward dilated convolutional units instead of recurrent ones, we were able to achieve comparable results to current state-of-the-art models on two question answering tasks. Additionally, we achieved significant speed improvements of up to two orders of magnitude in question answering tasks.", "In this study, we examine the reinstatement process described by Ritter et al. (2018) and identify two types of neurons that appear in the working memory of the agent (an epLSTM cell) when it is trained with episodic meta-reinforcement learning on a version of the Harlow visual fixation task that involves episodes. More specifically, Abstract neurons store information that is common to multiple tasks, whereas Episodic neurons contain details specific to a particular task episode.", "The rate-distortion-perception function (RDPF), introduced by Blau and Michaeli in 2019, offers a versatile framework for examining realism and distortion in lossy compression. While similar to the rate-distortion function, it remains uncertain whether there are encoding and decoding mechanisms capable of attaining the rates implied by the RDPF. Following the findings of Li and El Gamal in 2018, our research demonstrates that stochastic, variable-length codes can effectively realize the RDPF. Moreover, we establish that for this category of codes, the RDPF serves as a lower-bound on the achievable rate.", "In this paper, we introduce Neural Phrase-based Machine Translation (NPMT). Our approach incorporates phrase structures into the output sequences by leveraging Sleep-WAke Networks (SWAN), a segmentation-based sequence modeling method. To address the strict alignment requirement of SWAN, we introduce a new layer that enables (soft) local reordering of input sequences. Unlike traditional neural machine translation (NMT) models, NPMT does not rely on attention-based decoding mechanisms. Instead, it directly generates phrases in a sequential manner, allowing for linear-time decoding. Our experiments demonstrate that NPMT outperforms strong NMT baselines on IWSLT 2014 German-English/English-German and IWSLT 2015 English-Vietnamese translation tasks. Additionally, our method generates coherent phrases in the target languages.", "This passage reveals the importance of utilizing sparse representations of input data as a strategic defense against adversarial perturbations that can lead to errors in deep neural networks. The study not only demonstrates the effectiveness of sparsity in linear classifiers against specific attacks but also introduces the concept of a \"locally linear\" model for developing theoretical approaches to both attacks and defenses in deep neural networks. The experimental findings with the MNIST dataset further support the effectiveness of the suggested sparsifying front end.", "We introduce a novel method, named Supervised Policy Update (SPU), for deep reinforcement learning that is highly efficient with samples. SPU utilizes data from the current policy to formulate and solve a constrained optimization problem within the non-parameterized proximal policy space. By employing supervised regression, SPU transforms the optimal non-parameterized policy into a parameterized one, allowing for the generation of new samples. This approach is versatile, accommodating both discrete and continuous action spaces and a diverse range of proximity constraints for the non-parameterized optimization. Our research demonstrates how this methodology can effectively tackle Natural Policy Gradient, Trust Region Policy Optimization (NPG/TRPO), and Proximal Policy Optimization (PPO) problems. Notably, the implementation of SPU is notably less complex than TRPO. Through comprehensive experiments, we illustrate that SPU outperforms TRPO in Mujoco simulated robotic tasks and surpasses PPO in Atari video game tasks in terms of sample efficiency.", "We introduce a synthetic dataset, Moving Symbols, to analyze video prediction networks objectively. By controlling variations in the dataset, we identify shortcomings in a leading approach and suggest a more meaningful performance metric for better experimental interpretation. Our dataset offers standardized test cases to enhance comprehension and enhance the learned representations of these networks. Access the code at https://github.com/rszeto/moving-symbols."]